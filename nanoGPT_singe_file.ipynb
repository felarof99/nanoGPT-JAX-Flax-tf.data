{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "# jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "92cf26e3-cdee-46e1-da90-ae2f42dc966f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls     # chanel info size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHFANuKyilVM",
        "outputId": "5f9637ba-9fc3-4e15-ff54-b028e92558ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  dataset.py  model.py                   nanoGPT_singe_file.ipynb  trainer.py\n",
            "\u001b[01;34mdata\u001b[0m/    LICENSE     nanoGPT_JAX_JAX_JAX.ipynb  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "import dataset\n",
        "import model\n",
        "import trainer\n",
        "\n",
        "importlib.reload(dataset)\n",
        "importlib.reload(model)\n",
        "importlib.reload(trainer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Lwn46KOkxx",
        "outputId": "bf90cc08-42e8-402f-eb15-bf7f6c975d47"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/nanoGPT-JAX-JAX-JAX/dataset.py:49: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  data = jnp.array(_encode(text, self.stoi), dtype=jnp.int64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'trainer' from '/content/nanoGPT-JAX-JAX-JAX/trainer.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset.Dataset()"
      ],
      "metadata": {
        "id": "klG0YRl_cWHp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.run_train_step()"
      ],
      "metadata": {
        "id": "IHMmuzHoOc8l",
        "outputId": "8938ada4-d873-4f1f-ab5b-ede4e1ccea0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 4.74829 epoch 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pmapping"
      ],
      "metadata": {
        "id": "REnxRDB6X1SB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify using flax multihead attention"
      ],
      "metadata": {
        "id": "Y0YxWb75OJlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_attention_outputs(custom_attention, flax_attention, input_shape, num_heads, head_size, rng_key):\n",
        "    # Create dummy input\n",
        "    x = jax.random.normal(rng_key, input_shape)\n",
        "\n",
        "    # Initialize custom attention\n",
        "    custom_params = custom_attention.init(rng_key, x, training=True)\n",
        "    custom_output = custom_attention.apply(custom_params, x, training=True, rngs={'dropout': rng_key})\n",
        "\n",
        "    # Initialize Flax attention\n",
        "    flax_params = flax_attention.init(rng_key, x, x, x)\n",
        "    flax_output = flax_attention.apply(flax_params, x, x, x)\n",
        "\n",
        "    print(\"custom_output: \", custom_output)\n",
        "    print(\"flax_output: \", flax_output)\n",
        "\n",
        "    # Compare outputs\n",
        "    return jnp.isclose(custom_output, flax_output, atol=1e-5).all()"
      ],
      "metadata": {
        "id": "9ZyBx0FtoHCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng_key = jax.random.PRNGKey(0)\n",
        "input_shape = (1, 2, 4)  # (batch_size, sequence_length, feature_size)\n",
        "num_heads = 4\n",
        "head_size = 16"
      ],
      "metadata": {
        "id": "oqRFw2VpoPOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom attention\n",
        "custom_attention = model.MultiHeadAttentionBatch(num_heads=num_heads, head_size=head_size, T=input_shape[1])\n",
        "\n",
        "# Flax attention\n",
        "flax_attention = nn.MultiHeadDotProductAttention(num_heads=num_heads, qkv_features=head_size * num_heads, out_features=head_size * num_heads)\n"
      ],
      "metadata": {
        "id": "XSbv5LgaoJBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = compare_attention_outputs(custom_attention, flax_attention, input_shape, num_heads, head_size, rng_key)\n",
        "print(\"Are the attention outputs close?\", result)"
      ],
      "metadata": {
        "id": "GXd_SnvQoc_R",
        "outputId": "88210b97-bdf2-4218-80db-2cf5410a75b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom_output:  [[[ 1.8267553   0.2545625   0.51664734  1.872377    0.\n",
            "   -0.24741195  0.06325258 -0.4732108   0.97036505  0.\n",
            "    1.2170275   1.5578686   1.0638489   0.          2.772833\n",
            "   -0.41109625  0.444793   -0.08247733  0.         -0.18067323\n",
            "    0.          0.          0.6723873  -0.93943655 -0.3522747\n",
            "    1.2153784  -3.7089698   1.3073872  -0.6657839  -0.5994085\n",
            "   -0.33070773 -1.8484493   0.37312767  0.44226554  0.60474485\n",
            "    2.2404766   0.         -1.8605132  -2.4844682  -0.56995404\n",
            "   -0.1442299   1.2074916  -0.11788648  2.850931    0.33974466\n",
            "    2.3744946  -2.746928    0.685969   -0.92724115 -1.0124649\n",
            "    0.          0.          1.3646483   0.4259958   1.1758763\n",
            "   -0.8295348   0.3146336   0.38039386 -1.96878    -1.0014266\n",
            "    0.88716567  1.783647    0.57467306  0.        ]\n",
            "  [ 0.00777232  0.8190602   2.6580398   1.651423   -0.9469865\n",
            "    0.48011455 -0.9287533   0.          0.         -2.8874931\n",
            "    0.60840005  2.0658875   0.35624415  0.          0.\n",
            "    0.70599437  0.5896166   1.2817444  -2.1008098  -0.04484057\n",
            "   -1.4275442   0.72321385  0.22759527  1.5051701   0.00882745\n",
            "    0.         -2.986158    0.5997018   0.7692054  -0.82710356\n",
            "   -0.1810503   0.          0.54273605  0.         -0.7080898\n",
            "    2.2388384   0.5093732  -0.23307195  0.          0.8846841\n",
            "   -0.43849385 -0.07484592  0.          2.513607    0.\n",
            "    1.1121328   0.5170551   2.5407615   0.          0.\n",
            "    0.83413124  0.57952935  0.4368621  -0.6022251   0.67910165\n",
            "    0.21055423  2.8181696   1.44193    -0.7840652   0.3328532\n",
            "    1.2413915   0.46679747  1.4598145   0.        ]]]\n",
            "flax_output:  [[[ 2.8895974e-02 -1.0068653e+00  1.2057748e+00  1.7973888e+00\n",
            "   -9.9489683e-01  1.1024659e+00 -3.2609969e-01  1.3099843e+00\n",
            "    3.7963891e-01 -6.6500354e-01 -2.2156236e+00  9.9098140e-01\n",
            "   -5.2030826e-01 -4.0043575e-01 -4.7597340e-01  6.1389470e-01\n",
            "   -5.1270604e-02  7.1665388e-01  3.6454529e-01  1.5936635e+00\n",
            "    2.7062860e-01 -2.4697018e+00  9.4948125e-01 -1.8499115e-01\n",
            "   -3.7676191e-01  1.8491125e-01 -2.2871125e-01 -1.4550415e+00\n",
            "   -3.6182284e-02  1.7561679e+00  5.6670117e-01  1.5644410e+00\n",
            "    2.3776472e-02  4.1427138e-01 -6.4342296e-01  3.9061794e-01\n",
            "   -2.4873943e+00  1.8754792e+00 -3.7327498e-01  5.1972145e-01\n",
            "    6.5622520e-01 -1.1356449e+00 -7.3058254e-01 -1.1278011e+00\n",
            "    3.8242584e-01 -5.6327289e-01 -1.0293421e+00 -3.2101333e-01\n",
            "    6.9993138e-03 -1.5518066e+00 -1.2681470e+00 -1.0305943e+00\n",
            "   -5.0882530e-01 -1.2005109e+00 -6.9858456e-01 -1.2420511e+00\n",
            "   -1.6567755e-01  3.1398809e-01  4.8796660e-01  5.3497815e-01\n",
            "   -1.6045654e+00 -5.6580853e-01 -1.4447480e-02 -2.5624591e-01]\n",
            "  [-3.1292903e-01 -2.8228211e-01  1.6164991e+00  1.1566637e+00\n",
            "   -1.7909843e-01  1.6738888e+00  1.9191897e-01  8.8188696e-01\n",
            "    3.4660101e-04 -6.1186695e-01 -1.4816654e+00  1.2603579e+00\n",
            "   -3.3277538e-01  7.8265357e-01 -8.8903624e-01  5.0843740e-01\n",
            "   -1.7042160e-03  4.8674318e-01  7.8109443e-01  2.0034916e+00\n",
            "    3.9721832e-01 -2.0879889e+00  6.5748179e-01 -2.9969342e-02\n",
            "   -5.1880574e-01  1.1667207e+00 -1.6108215e-01 -1.8761901e+00\n",
            "   -4.9229816e-01  2.1759119e+00  3.3186966e-01  1.3340666e+00\n",
            "    1.1307223e+00  3.8203084e-01  8.1939280e-02  2.2764298e-01\n",
            "   -2.6299930e+00  1.7664719e+00 -1.5143943e-01  7.9535151e-01\n",
            "    8.9765227e-01 -6.7262584e-01 -3.1963915e-01 -1.7064387e-01\n",
            "    8.3032340e-02 -8.6961055e-01 -8.8943326e-01 -1.3560627e+00\n",
            "   -1.2381132e+00 -8.6521959e-01 -1.4085336e+00 -1.1443344e+00\n",
            "   -3.0510187e-01 -1.2790594e+00 -1.1063838e-01 -8.6992276e-01\n",
            "   -3.7931356e-01  7.1076035e-02  2.8989238e-01 -5.1210642e-02\n",
            "   -1.1258061e+00 -7.6050615e-01  2.4350727e-01  2.7750367e-01]]]\n",
            "Are the attention outputs close? False\n"
          ]
        }
      ]
    }
  ]
}