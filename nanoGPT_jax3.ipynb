{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG",
        "outputId": "834bc929-306a-4d65-9bac-2c191fc7e89a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CpuDevice(id=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "982a7131-a0d9-4df8-9323-036161375999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dataclasses\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Config:\n",
        "    vocab_size: int = 66\n",
        "    batch_size: int = 8 # 512\n",
        "    block_size: int = 8 # 64\n",
        "    n_embed: int = 8 # 256\n",
        "    num_heads: int = 8\n",
        "    num_layers: int = 6\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "fnlWQ63kW0kd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "nwtZXHlFGr59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "id": "cJvA8JscWVyF",
        "outputId": "62ad2346-313f-4be5-f8e1-2c4874c3821b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-01 04:22:58--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  6.37MB/s    in 0.2s    \n",
            "\n",
            "2024-05-01 04:22:59 (6.37 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "\n",
        "# Below would result in a minibatch size of 32.\n",
        "BATCH_SIZE = config.batch_size # how many independent sequences will we process in parallel?\n",
        "BLOCK_SIZE = config.block_size # what is the maximum context length for predictions?\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Create chars vocubulary using all the unique characters in the text.\n",
        "chars = sorted(list(set(text)))\n",
        "VOCAB_SIZE = len(chars)\n",
        "\n",
        "# Create mapping from characters to integers.\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create reverse mapping from integers to characters.\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create encode, decode function.\n",
        "def encode(s: str, stoi: Mapping[str, int]) -> List[int]:\n",
        "  return [stoi[c] for c in s]\n",
        "\n",
        "def decode(tokens: List[int], itos: Mapping[int, str]) -> str:\n",
        "  return ''.join([itos[i] for i in tokens])\n",
        "\n",
        "println(encode(\"hii there\", stoi), decode(encode(\"hii there\", stoi), itos))\n",
        "\n",
        "# Let's now split up the data into train and validation sets.\n",
        "data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "\n",
        "def create_dataset(training: bool = True):\n",
        "  data = train_data if training else val_data\n",
        "  dataset = (tf.data.Dataset.from_tensor_slices(data)\n",
        "                .repeat()\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .as_numpy_iterator())\n",
        "  return dataset\n",
        "\n",
        "def get_batch(dataset):\n",
        "  batch = next(dataset)\n",
        "  return jnp.array(batch)\n",
        "\n",
        "train_dataset = create_dataset(training=True)\n",
        "val_dataset = create_dataset(training=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26cmngjtGo3T",
        "outputId": "d9e08754-cf91-4513-bca3-f44426e1a5ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e4f4011cb7ef>:36: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test dataset"
      ],
      "metadata": {
        "id": "6xNHrv8UIsbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch(train_dataset)\n",
        "println(\"inputs\", xb, \"inputs shape\", xb.shape)\n",
        "println(\"targets\", yb, \"targets shape\", yb.shape)\n",
        "# for b in range(BATCH_SIZE): # batch dimension\n",
        "#     for t in range(BLOCK_SIZE): # time dimension\n",
        "#         context = xb[b, :t+1]\n",
        "#         target = yb[b,t]\n",
        "#         print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "id": "Js5MiGZ2IuVD",
        "outputId": "dae4a494-d70f-4ed2-f975-7f760cb17c04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[18 47 56 57 58  1 15 47]\n",
            " [47 64 43 52 10  0 14 43]\n",
            " [53 56 43  1 61 43  1 54]\n",
            " [53 41 43 43 42  1 39 52]\n",
            " [ 1 44 59 56 58 46 43 56]\n",
            " [ 1 46 43 39 56  1 51 43]\n",
            " [57 54 43 39 49  8  0  0]\n",
            " [50 50 10  0 31 54 43 39]]\n",
            "inputs shape\n",
            "(8, 8)\n",
            "targets\n",
            "[[47 56 57 58  1 15 47 58]\n",
            " [64 43 52 10  0 14 43 44]\n",
            " [56 43  1 61 43  1 54 56]\n",
            " [41 43 43 42  1 39 52 63]\n",
            " [44 59 56 58 46 43 56  6]\n",
            " [46 43 39 56  1 51 43  1]\n",
            " [54 43 39 49  8  0  0 13]\n",
            " [50 10  0 31 54 43 39 49]]\n",
            "targets shape\n",
            "(8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "TYcDwpPDJn52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "class SingleHeadAttention(nn.Module):\n",
        "  \"\"\"Implements a simple SingleHeadAttention layer for a single example from batch.\"\"\"\n",
        "\n",
        "  head_size: int\n",
        "  num_tokens: int\n",
        "  dropout_rate: float = 0.2\n",
        "  use_causal_mask: bool = True  # if True, only attend to past tokens.\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, tokens: jnp.array, training: bool):\n",
        "    \"\"\"Tokens, each with some channel dim.\"\"\"\n",
        "    # Use separate single dense layers for calculating keys, query, values\n",
        "    keys = nn.Dense(self.head_size, use_bias=False)(tokens)\n",
        "    queries = nn.Dense(self.head_size, use_bias=False)(tokens)\n",
        "    values = nn.Dense(self.head_size, use_bias=False)(tokens)\n",
        "\n",
        "    mask = (\n",
        "        jnp.tril(jnp.ones(shape=(self.num_tokens, self.num_tokens)))\n",
        "        if self.use_causal_mask\n",
        "        else jnp.ones(shape=(self.num_tokens, self.num_tokens))\n",
        "    )\n",
        "\n",
        "    # compute attention score.\n",
        "    # import pdb; pdb.set_trace()\n",
        "    wei = jnp.dot(queries, keys.T) / jnp.sqrt(self.head_size)\n",
        "    wei = jnp.where(mask == 0, -jnp.inf, wei)\n",
        "    wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "    attention_values = jnp.dot(\n",
        "        wei, values\n",
        "    )  # (num_tokens, num_tokens) * (num_tokens, head_size)\n",
        "    attention_values = nn.Dropout(rate=self.dropout_rate, deterministic=True)(\n",
        "        attention_values\n",
        "    )\n",
        "    return attention_values  # (num_tokens, head_size)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"Implements a MultiHeadAttention layer for a single example from batch.\"\"\"\n",
        "\n",
        "  head_size: int\n",
        "  num_heads: int\n",
        "  num_tokens: int\n",
        "  dropout_rate: float = 0.2\n",
        "\n",
        "  def setup(self):\n",
        "    self.heads = [\n",
        "        SingleHeadAttention(\n",
        "            head_size=self.head_size, num_tokens=self.num_tokens\n",
        "        )\n",
        "        for _ in range(self.num_heads)\n",
        "    ]\n",
        "\n",
        "    # Project concatenated output from all attention heads to final output\n",
        "    # dimension, which is head_size * num_heads.\n",
        "    self.projection = nn.Dense(features=self.num_heads * self.head_size)\n",
        "    self.dropout = nn.Dropout(rate=self.dropout_rate, deterministic=True)\n",
        "\n",
        "  def __call__(self, tokens: jnp.array, training: bool):\n",
        "    output_from_each_head = []\n",
        "    for h in self.heads:\n",
        "      head_output = h(tokens, training)\n",
        "      output_from_each_head.append(head_output)\n",
        "\n",
        "    # Run multiple attention heads in parallel and concatenate\n",
        "    # their output along channel dimension, i.e., dim==-1\n",
        "    out_from_all_heads = jnp.concatenate(output_from_each_head, axis=-1)\n",
        "\n",
        "    projection = self.projection(out_from_all_heads)\n",
        "    return self.dropout(projection)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  output_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    # Attention paper uses 4 times token_info_size when doing linear transformation\n",
        "    # and then projects it back to token_info_size in linear transformation layer.\n",
        "    self.ffwd = nn.Dense(features=4 * self.output_size)\n",
        "    self.projection = nn.Dense(self.output_size)\n",
        "\n",
        "  def __call__(self, x, training: bool):\n",
        "    x = nn.relu(self.ffwd(x))\n",
        "    x = self.projection(x)\n",
        "    return x\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "  num_heads: int\n",
        "  # output_size = head_size * num_heads, is the final embedding dimension you get after concatenating from all heads.\n",
        "  output_size: int\n",
        "  num_tokens: int\n",
        "\n",
        "  def setup(self):\n",
        "    # communication.\n",
        "    # each single head will produce head_size worth of info for key, value, querie. You concatenate all of them to get the final output_size.\n",
        "    self.head_size = self.output_size // self.num_heads\n",
        "    self.self_attention_heads = MultiHeadAttention(num_heads=self.num_heads,\n",
        "                                                   head_size = self.head_size,\n",
        "                                                   num_tokens=self.num_tokens)\n",
        "\n",
        "    # computation.\n",
        "    self.computation_layer = FeedForward(output_size=self.output_size)\n",
        "\n",
        "    self.ln1 = nn.LayerNorm()\n",
        "    self.ln2 = nn.LayerNorm()\n",
        "\n",
        "    self.dropout = nn.Dropout(rate=0.2, deterministic=True)\n",
        "\n",
        "  def __call__(self, x, training: bool):\n",
        "    # transformer encoder forward pass\n",
        "    x = x + self.self_attention_heads(self.ln1(x), training)\n",
        "\n",
        "    x = x + self.computation_layer(self.ln2(x), training)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    return x\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "  num_tokens: int # block size, i.e., number of tokens attention block is looking at once\n",
        "  num_heads: int\n",
        "  num_layers: int\n",
        "\n",
        "  def setup(self):\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.num_tokens, features=self.n_embed)\n",
        "\n",
        "    # Since, there are 4 heads, each head only needs to output token_info of size 8.\n",
        "    # Concantenate token_info from all 4 heards, gives us 32\n",
        "    self.blocks = [\n",
        "        TransformerEncoderBlock(num_heads=self.num_heads,\n",
        "                                output_size=self.n_embed,\n",
        "                                num_tokens=self.num_tokens) for _ in range(self.num_layers)\n",
        "    ]\n",
        "    self.ln = nn.LayerNorm()\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array, training: bool):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "    # generate emb for each token. output: (num_tokens, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    # feed x into self-attention head.\n",
        "    # language model, forward pass, block_of_tokens\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.blocks[i](x, training)\n",
        "\n",
        "    x = self.ln(x)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n",
        "\n",
        "    return token_logits\n",
        "\n",
        "\n",
        "class LanguageModelBatch(nn.Module):\n",
        "  \"\"\"Extends MultiHeadAttention to work on a batch of data.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "  num_tokens: int # block size, i.e., number of tokens attention block is looking at once\n",
        "  num_heads: int\n",
        "  num_layers: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, tokens: jnp.array, training: bool):\n",
        "    return jax.vmap(LanguageModel(\n",
        "        vocab_size=self.vocab_size,\n",
        "        n_embed=self.n_embed,\n",
        "        num_tokens=self.num_tokens,\n",
        "        num_heads=self.num_heads,\n",
        "        num_layers=self.num_layers),\n",
        "                    in_axes=(0, None),  # tokens, training\n",
        "                    out_axes=(0),)(tokens, training)"
      ],
      "metadata": {
        "id": "T-EplD3kJspx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(params, state, batch, training, rng):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs, training, rngs={\"dropout\": rng})\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "aq7qKwvaMMJR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass(state, batch, training, rng):\n",
        "  grad_fn = jax.value_and_grad(forward_pass, argnums=(0))\n",
        "  loss, grads = grad_fn(state.params, state, batch, training, rng)\n",
        "\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state, loss"
      ],
      "metadata": {
        "id": "18htMbRiNLSh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass_pmap(state, batch, training, rng):\n",
        "  grad_fn = jax.value_and_grad(forward_pass, argnums=(0))\n",
        "  loss, grads = grad_fn(state.params, state, batch, training, rng)\n",
        "\n",
        "  loss = jax.lax.pmean(loss, axis_name=\"devices\")\n",
        "  grads = jax.lax.pmean(grads, axis_name=\"devices\")\n",
        "\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state, loss"
      ],
      "metadata": {
        "id": "ED5UYEv8RklP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(state, batch, training, rng):\n",
        "  state, loss = backward_pass(state, batch, training, rng)\n",
        "  return state, loss\n",
        "\n",
        "train_step_pmap = jax.pmap(\n",
        "    jax.jit(train_step), in_axes=(0, 0, None, 0), out_axes=(0), axis_name=\"devices\")"
      ],
      "metadata": {
        "id": "qDqK-I-rNCHp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_pmap(dataset):\n",
        "  inputs, targets = get_batch(dataset)\n",
        "  inputs = inputs.reshape((jax.device_count(), -1, inputs.shape[-1]))\n",
        "  targets = targets.reshape((jax.device_count(), -1, targets.shape[-1]))\n",
        "  return inputs, targets\n"
      ],
      "metadata": {
        "id": "La2WfX9LUKpO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModelBatch(vocab_size=config.vocab_size,\n",
        "                      n_embed=config.n_embed,\n",
        "                      num_tokens=config.block_size,\n",
        "                      num_heads=config.num_heads,\n",
        "                      num_layers=config.num_layers)"
      ],
      "metadata": {
        "id": "J8yhi01bUR5z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = get_batch(train_dataset)\n",
        "inputs.shape, targets.shape"
      ],
      "metadata": {
        "id": "GSTEXCxNU5Q7",
        "outputId": "2342c33a-4358-4a81-f84c-f0b79fecff86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 8), (8, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputsp, targetsp = get_batch_pmap(train_dataset)\n",
        "inputsp.shape, targetsp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJzqX4JzUZSz",
        "outputId": "e35effd6-292d-4b68-8571-af5f1c86cbb6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 8, 8), (1, 8, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, params = model.init_with_output(jax.random.PRNGKey(99), inputs, training=False)\n",
        "params = params[\"params\"]\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "id": "C-OSerO_VOoZ",
        "outputId": "5ada2c69-7f36-4810-b77d-f28220d4c503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8, 66)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optax.adam(learning_rate=0.0001)\n",
        "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=opt)"
      ],
      "metadata": {
        "id": "MVloxbBKMQkV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = jax.device_put_replicated(state, jax.local_devices())"
      ],
      "metadata": {
        "id": "DvjPw2u7TOp_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backward_pass(state, get_batch(train_dataset), False, jax.random.PRNGKey(99))"
      ],
      "metadata": {
        "id": "mdaOjUvwNXZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states, loss = train_step_pmap(states, get_batch_pmap(train_dataset), False, jax.random.split(jax.random.PRNGKey(9),\n",
        "                                                                                              num=DEVICE_COUNT))"
      ],
      "metadata": {
        "id": "oyNTZdwGUzkb"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rngs = jax.random.split(jax.random.PRNGKey(9), num=DEVICE_COUNT)\n",
        "for step in range(1):\n",
        "  rngs = jax.random.split(rngs[0], num=DEVICE_COUNT)\n",
        "  train_batch = get_batch_pmap(train_dataset)\n",
        "  states, loss = train_step_pmap(states, train_batch, False, rngs)\n",
        "\n",
        "  print(\"loss\", loss[0], \"step\", step) if step%100==0 else None"
      ],
      "metadata": {
        "id": "Mdnn4TP8cPlX",
        "outputId": "e2145cc9-634c-4ae2-a137-217451521e54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 4.82799 step 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating"
      ],
      "metadata": {
        "id": "FWLBGB5VqQwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T = config.block_size\n",
        "\n",
        "state = jax.tree_map(lambda x: x[0], states)\n",
        "\n",
        "state_apply_jit = jax.jit(state.apply_fn)\n",
        "\n",
        "context = jnp.tile(jnp.array([52], dtype=jnp.int32), T)\n",
        "context = context[None, -T:]\n",
        "key = jrand.PRNGKey(99)\n",
        "\n",
        "for _ in range(100):\n",
        "  next_token_logits = state_apply_jit({\"params\": state.params}, context[:, -T:], False)\n",
        "\n",
        "  key, split_key = jrand.split(key)\n",
        "  new_token = jax.random.categorical(key, next_token_logits[:, -1, :], axis=-1, shape=(1, 1))\n",
        "\n",
        "  context = jnp.concatenate([context, new_token], axis=1)\n",
        "\n",
        "\n",
        "print(decode(context.tolist()[0], itos))\n"
      ],
      "metadata": {
        "id": "JeZ-lGtoqSpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}