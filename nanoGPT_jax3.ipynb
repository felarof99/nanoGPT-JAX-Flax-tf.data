{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()\n",
        "jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG",
        "outputId": "d97d2f0c-7fcd-4e65-ec10-f2446eb4c319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "b859533d-d252-49cb-fbc0-6314880e6c9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "nwtZXHlFGr59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "\n",
        "# Below would result in a minibatch size of 32.\n",
        "BATCH_SIZE = 32 # how many independent sequences will we process in parallel?\n",
        "BLOCK_SIZE = 16 # what is the maximum context length for predictions?\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Create chars vocubulary using all the unique characters in the text.\n",
        "chars = sorted(list(set(text)))\n",
        "VOCAB_SIZE = len(chars)\n",
        "\n",
        "# Create mapping from characters to integers.\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create reverse mapping from integers to characters.\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create encode, decode function.\n",
        "def encode(s: str, stoi: Mapping[str, int]) -> List[int]:\n",
        "  return [stoi[c] for c in s]\n",
        "\n",
        "def decode(tokens: List[int], itos: Mapping[int, str]) -> str:\n",
        "  return ''.join([itos[i] for i in tokens])\n",
        "\n",
        "println(encode(\"hii there\", stoi), decode(encode(\"hii there\", stoi), itos))\n",
        "\n",
        "# Let's now split up the data into train and validation sets.\n",
        "data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "\n",
        "def create_dataset(training: bool = True):\n",
        "  data = train_data if training else val_data\n",
        "  dataset = (tf.data.Dataset.from_tensor_slices(data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "  return dataset\n",
        "\n",
        "def get_batch(dataset):\n",
        "  batch = next(dataset)\n",
        "  return jnp.array(batch)\n",
        "\n",
        "train_dataset = create_dataset(training=True)\n",
        "val_dataset = create_dataset(training=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26cmngjtGo3T",
        "outputId": "d320057c-353f-4b4b-fadb-c7056cdde347"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 03:35:25--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-04-25 03:35:25 (19.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n",
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-63588fe4ee46>:38: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test dataset"
      ],
      "metadata": {
        "id": "6xNHrv8UIsbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch(train_dataset)\n",
        "println(\"inputs\", xb, \"inputs shape\", xb.shape)\n",
        "println(\"targets\", yb, \"targets shape\", yb.shape)\n",
        "for b in range(BATCH_SIZE): # batch dimension\n",
        "    for t in range(BLOCK_SIZE): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "id": "Js5MiGZ2IuVD",
        "outputId": "1fdb90e5-baea-40b8-da98-26ba1d4db879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14]\n",
            " [44 53 56 43  1 61 43  1 54 56 53 41 43 43 42  1]\n",
            " [52 63  1 44 59 56 58 46 43 56  6  1 46 43 39 56]\n",
            " [51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0]\n",
            " [54 43 39 49  6  1 57 54 43 39 49  8  0  0 18 47]\n",
            " [57 58  1 15 47 58 47 64 43 52 10  0 37 53 59  1]\n",
            " [56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1]\n",
            " [39 58 46 43 56  1 58 53  1 42 47 43  1 58 46 39]\n",
            " [ 1 58 53  1 44 39 51 47 57 46 12  0  0 13 50 50]\n",
            " [ 0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50]\n",
            " [43 42  8  0  0 18 47 56 57 58  1 15 47 58 47 64]\n",
            " [52 10  0 18 47 56 57 58  6  1 63 53 59  1 49 52]\n",
            " [61  1 15 39 47 59 57  1 25 39 56 41 47 59 57  1]\n",
            " [57  1 41 46 47 43 44  1 43 52 43 51 63  1 58 53]\n",
            " [58 46 43  1 54 43 53 54 50 43  8  0  0 13 50 50]\n",
            " [ 0 35 43  1 49 52 53 61  5 58  6  1 61 43  1 49]\n",
            " [53 61  5 58  8  0  0 18 47 56 57 58  1 15 47 58]\n",
            " [64 43 52 10  0 24 43 58  1 59 57  1 49 47 50 50]\n",
            " [46 47 51  6  1 39 52 42  1 61 43  5 50 50  1 46]\n",
            " [60 43  1 41 53 56 52  1 39 58  1 53 59 56  1 53]\n",
            " [52  1 54 56 47 41 43  8  0 21 57  5 58  1 39  1]\n",
            " [43 56 42 47 41 58 12  0  0 13 50 50 10  0 26 53]\n",
            " [51 53 56 43  1 58 39 50 49 47 52 45  1 53 52  5]\n",
            " [11  1 50 43 58  1 47 58  1 40 43  1 42 53 52 43]\n",
            " [ 1 39 61 39 63  6  1 39 61 39 63  2  0  0 31 43]\n",
            " [53 52 42  1 15 47 58 47 64 43 52 10  0 27 52 43]\n",
            " [61 53 56 42  6  1 45 53 53 42  1 41 47 58 47 64]\n",
            " [52 57  8  0  0 18 47 56 57 58  1 15 47 58 47 64]\n",
            " [52 10  0 35 43  1 39 56 43  1 39 41 41 53 59 52]\n",
            " [43 42  1 54 53 53 56  1 41 47 58 47 64 43 52 57]\n",
            " [ 1 58 46 43  1 54 39 58 56 47 41 47 39 52 57  1]\n",
            " [53 53 42  8  0 35 46 39 58  1 39 59 58 46 53 56]]\n",
            "inputs shape\n",
            "(32, 16)\n",
            "targets\n",
            "[[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43]\n",
            " [53 56 43  1 61 43  1 54 56 53 41 43 43 42  1 39]\n",
            " [63  1 44 59 56 58 46 43 56  6  1 46 43 39 56  1]\n",
            " [43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31]\n",
            " [43 39 49  6  1 57 54 43 39 49  8  0  0 18 47 56]\n",
            " [58  1 15 47 58 47 64 43 52 10  0 37 53 59  1 39]\n",
            " [43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56]\n",
            " [58 46 43 56  1 58 53  1 42 47 43  1 58 46 39 52]\n",
            " [58 53  1 44 39 51 47 57 46 12  0  0 13 50 50 10]\n",
            " [30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60]\n",
            " [42  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43]\n",
            " [10  0 18 47 56 57 58  6  1 63 53 59  1 49 52 53]\n",
            " [ 1 15 39 47 59 57  1 25 39 56 41 47 59 57  1 47]\n",
            " [ 1 41 46 47 43 44  1 43 52 43 51 63  1 58 53  1]\n",
            " [46 43  1 54 43 53 54 50 43  8  0  0 13 50 50 10]\n",
            " [35 43  1 49 52 53 61  5 58  6  1 61 43  1 49 52]\n",
            " [61  5 58  8  0  0 18 47 56 57 58  1 15 47 58 47]\n",
            " [43 52 10  0 24 43 58  1 59 57  1 49 47 50 50  1]\n",
            " [47 51  6  1 39 52 42  1 61 43  5 50 50  1 46 39]\n",
            " [43  1 41 53 56 52  1 39 58  1 53 59 56  1 53 61]\n",
            " [ 1 54 56 47 41 43  8  0 21 57  5 58  1 39  1 60]\n",
            " [56 42 47 41 58 12  0  0 13 50 50 10  0 26 53  1]\n",
            " [53 56 43  1 58 39 50 49 47 52 45  1 53 52  5 58]\n",
            " [ 1 50 43 58  1 47 58  1 40 43  1 42 53 52 43 10]\n",
            " [39 61 39 63  6  1 39 61 39 63  2  0  0 31 43 41]\n",
            " [52 42  1 15 47 58 47 64 43 52 10  0 27 52 43  1]\n",
            " [53 56 42  6  1 45 53 53 42  1 41 47 58 47 64 43]\n",
            " [57  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43]\n",
            " [10  0 35 43  1 39 56 43  1 39 41 41 53 59 52 58]\n",
            " [42  1 54 53 53 56  1 41 47 58 47 64 43 52 57  6]\n",
            " [58 46 43  1 54 39 58 56 47 41 47 39 52 57  1 45]\n",
            " [53 42  8  0 35 46 39 58  1 39 59 58 46 53 56 47]]\n",
            "targets shape\n",
            "(32, 16)\n",
            "when input is [18] the target: 47\n",
            "when input is [18, 47] the target: 56\n",
            "when input is [18, 47, 56] the target: 57\n",
            "when input is [18, 47, 56, 57] the target: 58\n",
            "when input is [18, 47, 56, 57, 58] the target: 1\n",
            "when input is [18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58] the target: 47\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47] the target: 64\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64] the target: 43\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43] the target: 52\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52] the target: 10\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10] the target: 0\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0] the target: 14\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14] the target: 43\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 43\n",
            "when input is [44, 53, 56, 43] the target: 1\n",
            "when input is [44, 53, 56, 43, 1] the target: 61\n",
            "when input is [44, 53, 56, 43, 1, 61] the target: 43\n",
            "when input is [44, 53, 56, 43, 1, 61, 43] the target: 1\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1] the target: 54\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54] the target: 56\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56] the target: 53\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53] the target: 41\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41] the target: 43\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43] the target: 43\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43] the target: 42\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42] the target: 1\n",
            "when input is [44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1] the target: 39\n",
            "when input is [52] the target: 63\n",
            "when input is [52, 63] the target: 1\n",
            "when input is [52, 63, 1] the target: 44\n",
            "when input is [52, 63, 1, 44] the target: 59\n",
            "when input is [52, 63, 1, 44, 59] the target: 56\n",
            "when input is [52, 63, 1, 44, 59, 56] the target: 58\n",
            "when input is [52, 63, 1, 44, 59, 56, 58] the target: 46\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46] the target: 43\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43] the target: 56\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56] the target: 6\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6] the target: 1\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1] the target: 46\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46] the target: 43\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43] the target: 39\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39] the target: 56\n",
            "when input is [52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56] the target: 1\n",
            "when input is [51] the target: 43\n",
            "when input is [51, 43] the target: 1\n",
            "when input is [51, 43, 1] the target: 57\n",
            "when input is [51, 43, 1, 57] the target: 54\n",
            "when input is [51, 43, 1, 57, 54] the target: 43\n",
            "when input is [51, 43, 1, 57, 54, 43] the target: 39\n",
            "when input is [51, 43, 1, 57, 54, 43, 39] the target: 49\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49] the target: 8\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8] the target: 0\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0] the target: 0\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0] the target: 13\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13] the target: 50\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50] the target: 50\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50] the target: 10\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10] the target: 0\n",
            "when input is [51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0] the target: 31\n",
            "when input is [54] the target: 43\n",
            "when input is [54, 43] the target: 39\n",
            "when input is [54, 43, 39] the target: 49\n",
            "when input is [54, 43, 39, 49] the target: 6\n",
            "when input is [54, 43, 39, 49, 6] the target: 1\n",
            "when input is [54, 43, 39, 49, 6, 1] the target: 57\n",
            "when input is [54, 43, 39, 49, 6, 1, 57] the target: 54\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54] the target: 43\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43] the target: 39\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39] the target: 49\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49] the target: 8\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8] the target: 0\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0] the target: 0\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0] the target: 18\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18] the target: 47\n",
            "when input is [54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47] the target: 56\n",
            "when input is [57] the target: 58\n",
            "when input is [57, 58] the target: 1\n",
            "when input is [57, 58, 1] the target: 15\n",
            "when input is [57, 58, 1, 15] the target: 47\n",
            "when input is [57, 58, 1, 15, 47] the target: 58\n",
            "when input is [57, 58, 1, 15, 47, 58] the target: 47\n",
            "when input is [57, 58, 1, 15, 47, 58, 47] the target: 64\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64] the target: 43\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43] the target: 52\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52] the target: 10\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10] the target: 0\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0] the target: 37\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37] the target: 53\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53] the target: 59\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59] the target: 1\n",
            "when input is [57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59, 1] the target: 39\n",
            "when input is [56] the target: 43\n",
            "when input is [56, 43] the target: 1\n",
            "when input is [56, 43, 1] the target: 39\n",
            "when input is [56, 43, 1, 39] the target: 50\n",
            "when input is [56, 43, 1, 39, 50] the target: 50\n",
            "when input is [56, 43, 1, 39, 50, 50] the target: 1\n",
            "when input is [56, 43, 1, 39, 50, 50, 1] the target: 56\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56] the target: 43\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43] the target: 57\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57] the target: 53\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53] the target: 50\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50] the target: 60\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50, 60] the target: 43\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50, 60, 43] the target: 42\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50, 60, 43, 42] the target: 1\n",
            "when input is [56, 43, 1, 39, 50, 50, 1, 56, 43, 57, 53, 50, 60, 43, 42, 1] the target: 56\n",
            "when input is [39] the target: 58\n",
            "when input is [39, 58] the target: 46\n",
            "when input is [39, 58, 46] the target: 43\n",
            "when input is [39, 58, 46, 43] the target: 56\n",
            "when input is [39, 58, 46, 43, 56] the target: 1\n",
            "when input is [39, 58, 46, 43, 56, 1] the target: 58\n",
            "when input is [39, 58, 46, 43, 56, 1, 58] the target: 53\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53] the target: 1\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1] the target: 42\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42] the target: 47\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47] the target: 43\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43] the target: 1\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43, 1] the target: 58\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43, 1, 58] the target: 46\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43, 1, 58, 46] the target: 39\n",
            "when input is [39, 58, 46, 43, 56, 1, 58, 53, 1, 42, 47, 43, 1, 58, 46, 39] the target: 52\n",
            "when input is [1] the target: 58\n",
            "when input is [1, 58] the target: 53\n",
            "when input is [1, 58, 53] the target: 1\n",
            "when input is [1, 58, 53, 1] the target: 44\n",
            "when input is [1, 58, 53, 1, 44] the target: 39\n",
            "when input is [1, 58, 53, 1, 44, 39] the target: 51\n",
            "when input is [1, 58, 53, 1, 44, 39, 51] the target: 47\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47] the target: 57\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57] the target: 46\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46] the target: 12\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12] the target: 0\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0] the target: 0\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0, 0] the target: 13\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0, 0, 13] the target: 50\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0, 0, 13, 50] the target: 50\n",
            "when input is [1, 58, 53, 1, 44, 39, 51, 47, 57, 46, 12, 0, 0, 13, 50, 50] the target: 10\n",
            "when input is [0] the target: 30\n",
            "when input is [0, 30] the target: 43\n",
            "when input is [0, 30, 43] the target: 57\n",
            "when input is [0, 30, 43, 57] the target: 53\n",
            "when input is [0, 30, 43, 57, 53] the target: 50\n",
            "when input is [0, 30, 43, 57, 53, 50] the target: 60\n",
            "when input is [0, 30, 43, 57, 53, 50, 60] the target: 43\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43] the target: 42\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42] the target: 8\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8] the target: 1\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1] the target: 56\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56] the target: 43\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56, 43] the target: 57\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56, 43, 57] the target: 53\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56, 43, 57, 53] the target: 50\n",
            "when input is [0, 30, 43, 57, 53, 50, 60, 43, 42, 8, 1, 56, 43, 57, 53, 50] the target: 60\n",
            "when input is [43] the target: 42\n",
            "when input is [43, 42] the target: 8\n",
            "when input is [43, 42, 8] the target: 0\n",
            "when input is [43, 42, 8, 0] the target: 0\n",
            "when input is [43, 42, 8, 0, 0] the target: 18\n",
            "when input is [43, 42, 8, 0, 0, 18] the target: 47\n",
            "when input is [43, 42, 8, 0, 0, 18, 47] the target: 56\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56] the target: 57\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57] the target: 58\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58] the target: 1\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58] the target: 47\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47] the target: 64\n",
            "when input is [43, 42, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64] the target: 43\n",
            "when input is [52] the target: 10\n",
            "when input is [52, 10] the target: 0\n",
            "when input is [52, 10, 0] the target: 18\n",
            "when input is [52, 10, 0, 18] the target: 47\n",
            "when input is [52, 10, 0, 18, 47] the target: 56\n",
            "when input is [52, 10, 0, 18, 47, 56] the target: 57\n",
            "when input is [52, 10, 0, 18, 47, 56, 57] the target: 58\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58] the target: 6\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6] the target: 1\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1] the target: 63\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63] the target: 53\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53] the target: 59\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53, 59] the target: 1\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53, 59, 1] the target: 49\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53, 59, 1, 49] the target: 52\n",
            "when input is [52, 10, 0, 18, 47, 56, 57, 58, 6, 1, 63, 53, 59, 1, 49, 52] the target: 53\n",
            "when input is [61] the target: 1\n",
            "when input is [61, 1] the target: 15\n",
            "when input is [61, 1, 15] the target: 39\n",
            "when input is [61, 1, 15, 39] the target: 47\n",
            "when input is [61, 1, 15, 39, 47] the target: 59\n",
            "when input is [61, 1, 15, 39, 47, 59] the target: 57\n",
            "when input is [61, 1, 15, 39, 47, 59, 57] the target: 1\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1] the target: 25\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25] the target: 39\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39] the target: 56\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56] the target: 41\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41] the target: 47\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41, 47] the target: 59\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41, 47, 59] the target: 57\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41, 47, 59, 57] the target: 1\n",
            "when input is [61, 1, 15, 39, 47, 59, 57, 1, 25, 39, 56, 41, 47, 59, 57, 1] the target: 47\n",
            "when input is [57] the target: 1\n",
            "when input is [57, 1] the target: 41\n",
            "when input is [57, 1, 41] the target: 46\n",
            "when input is [57, 1, 41, 46] the target: 47\n",
            "when input is [57, 1, 41, 46, 47] the target: 43\n",
            "when input is [57, 1, 41, 46, 47, 43] the target: 44\n",
            "when input is [57, 1, 41, 46, 47, 43, 44] the target: 1\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1] the target: 43\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43] the target: 52\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52] the target: 43\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43] the target: 51\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51] the target: 63\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51, 63] the target: 1\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51, 63, 1] the target: 58\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51, 63, 1, 58] the target: 53\n",
            "when input is [57, 1, 41, 46, 47, 43, 44, 1, 43, 52, 43, 51, 63, 1, 58, 53] the target: 1\n",
            "when input is [58] the target: 46\n",
            "when input is [58, 46] the target: 43\n",
            "when input is [58, 46, 43] the target: 1\n",
            "when input is [58, 46, 43, 1] the target: 54\n",
            "when input is [58, 46, 43, 1, 54] the target: 43\n",
            "when input is [58, 46, 43, 1, 54, 43] the target: 53\n",
            "when input is [58, 46, 43, 1, 54, 43, 53] the target: 54\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54] the target: 50\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50] the target: 43\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43] the target: 8\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8] the target: 0\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0] the target: 0\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0, 0] the target: 13\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0, 0, 13] the target: 50\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0, 0, 13, 50] the target: 50\n",
            "when input is [58, 46, 43, 1, 54, 43, 53, 54, 50, 43, 8, 0, 0, 13, 50, 50] the target: 10\n",
            "when input is [0] the target: 35\n",
            "when input is [0, 35] the target: 43\n",
            "when input is [0, 35, 43] the target: 1\n",
            "when input is [0, 35, 43, 1] the target: 49\n",
            "when input is [0, 35, 43, 1, 49] the target: 52\n",
            "when input is [0, 35, 43, 1, 49, 52] the target: 53\n",
            "when input is [0, 35, 43, 1, 49, 52, 53] the target: 61\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61] the target: 5\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5] the target: 58\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58] the target: 6\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6] the target: 1\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6, 1] the target: 61\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6, 1, 61] the target: 43\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6, 1, 61, 43] the target: 1\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6, 1, 61, 43, 1] the target: 49\n",
            "when input is [0, 35, 43, 1, 49, 52, 53, 61, 5, 58, 6, 1, 61, 43, 1, 49] the target: 52\n",
            "when input is [53] the target: 61\n",
            "when input is [53, 61] the target: 5\n",
            "when input is [53, 61, 5] the target: 58\n",
            "when input is [53, 61, 5, 58] the target: 8\n",
            "when input is [53, 61, 5, 58, 8] the target: 0\n",
            "when input is [53, 61, 5, 58, 8, 0] the target: 0\n",
            "when input is [53, 61, 5, 58, 8, 0, 0] the target: 18\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18] the target: 47\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47] the target: 56\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56] the target: 57\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57] the target: 58\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57, 58] the target: 1\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [53, 61, 5, 58, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58] the target: 47\n",
            "when input is [64] the target: 43\n",
            "when input is [64, 43] the target: 52\n",
            "when input is [64, 43, 52] the target: 10\n",
            "when input is [64, 43, 52, 10] the target: 0\n",
            "when input is [64, 43, 52, 10, 0] the target: 24\n",
            "when input is [64, 43, 52, 10, 0, 24] the target: 43\n",
            "when input is [64, 43, 52, 10, 0, 24, 43] the target: 58\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58] the target: 1\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1] the target: 59\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59] the target: 57\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57] the target: 1\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57, 1] the target: 49\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57, 1, 49] the target: 47\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57, 1, 49, 47] the target: 50\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57, 1, 49, 47, 50] the target: 50\n",
            "when input is [64, 43, 52, 10, 0, 24, 43, 58, 1, 59, 57, 1, 49, 47, 50, 50] the target: 1\n",
            "when input is [46] the target: 47\n",
            "when input is [46, 47] the target: 51\n",
            "when input is [46, 47, 51] the target: 6\n",
            "when input is [46, 47, 51, 6] the target: 1\n",
            "when input is [46, 47, 51, 6, 1] the target: 39\n",
            "when input is [46, 47, 51, 6, 1, 39] the target: 52\n",
            "when input is [46, 47, 51, 6, 1, 39, 52] the target: 42\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42] the target: 1\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1] the target: 61\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61] the target: 43\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43] the target: 5\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43, 5] the target: 50\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43, 5, 50] the target: 50\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43, 5, 50, 50] the target: 1\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43, 5, 50, 50, 1] the target: 46\n",
            "when input is [46, 47, 51, 6, 1, 39, 52, 42, 1, 61, 43, 5, 50, 50, 1, 46] the target: 39\n",
            "when input is [60] the target: 43\n",
            "when input is [60, 43] the target: 1\n",
            "when input is [60, 43, 1] the target: 41\n",
            "when input is [60, 43, 1, 41] the target: 53\n",
            "when input is [60, 43, 1, 41, 53] the target: 56\n",
            "when input is [60, 43, 1, 41, 53, 56] the target: 52\n",
            "when input is [60, 43, 1, 41, 53, 56, 52] the target: 1\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1] the target: 39\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39] the target: 58\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58] the target: 1\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1] the target: 53\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1, 53] the target: 59\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1, 53, 59] the target: 56\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1, 53, 59, 56] the target: 1\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1, 53, 59, 56, 1] the target: 53\n",
            "when input is [60, 43, 1, 41, 53, 56, 52, 1, 39, 58, 1, 53, 59, 56, 1, 53] the target: 61\n",
            "when input is [52] the target: 1\n",
            "when input is [52, 1] the target: 54\n",
            "when input is [52, 1, 54] the target: 56\n",
            "when input is [52, 1, 54, 56] the target: 47\n",
            "when input is [52, 1, 54, 56, 47] the target: 41\n",
            "when input is [52, 1, 54, 56, 47, 41] the target: 43\n",
            "when input is [52, 1, 54, 56, 47, 41, 43] the target: 8\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8] the target: 0\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0] the target: 21\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21] the target: 57\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57] the target: 5\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57, 5] the target: 58\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57, 5, 58] the target: 1\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57, 5, 58, 1] the target: 39\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57, 5, 58, 1, 39] the target: 1\n",
            "when input is [52, 1, 54, 56, 47, 41, 43, 8, 0, 21, 57, 5, 58, 1, 39, 1] the target: 60\n",
            "when input is [43] the target: 56\n",
            "when input is [43, 56] the target: 42\n",
            "when input is [43, 56, 42] the target: 47\n",
            "when input is [43, 56, 42, 47] the target: 41\n",
            "when input is [43, 56, 42, 47, 41] the target: 58\n",
            "when input is [43, 56, 42, 47, 41, 58] the target: 12\n",
            "when input is [43, 56, 42, 47, 41, 58, 12] the target: 0\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0] the target: 0\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0] the target: 13\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13] the target: 50\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50] the target: 50\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50, 50] the target: 10\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50, 50, 10] the target: 0\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50, 50, 10, 0] the target: 26\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50, 50, 10, 0, 26] the target: 53\n",
            "when input is [43, 56, 42, 47, 41, 58, 12, 0, 0, 13, 50, 50, 10, 0, 26, 53] the target: 1\n",
            "when input is [51] the target: 53\n",
            "when input is [51, 53] the target: 56\n",
            "when input is [51, 53, 56] the target: 43\n",
            "when input is [51, 53, 56, 43] the target: 1\n",
            "when input is [51, 53, 56, 43, 1] the target: 58\n",
            "when input is [51, 53, 56, 43, 1, 58] the target: 39\n",
            "when input is [51, 53, 56, 43, 1, 58, 39] the target: 50\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50] the target: 49\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49] the target: 47\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47] the target: 52\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52] the target: 45\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52, 45] the target: 1\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52, 45, 1] the target: 53\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52, 45, 1, 53] the target: 52\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52, 45, 1, 53, 52] the target: 5\n",
            "when input is [51, 53, 56, 43, 1, 58, 39, 50, 49, 47, 52, 45, 1, 53, 52, 5] the target: 58\n",
            "when input is [11] the target: 1\n",
            "when input is [11, 1] the target: 50\n",
            "when input is [11, 1, 50] the target: 43\n",
            "when input is [11, 1, 50, 43] the target: 58\n",
            "when input is [11, 1, 50, 43, 58] the target: 1\n",
            "when input is [11, 1, 50, 43, 58, 1] the target: 47\n",
            "when input is [11, 1, 50, 43, 58, 1, 47] the target: 58\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58] the target: 1\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1] the target: 40\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40] the target: 43\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43] the target: 1\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 1] the target: 42\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 1, 42] the target: 53\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 1, 42, 53] the target: 52\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 1, 42, 53, 52] the target: 43\n",
            "when input is [11, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 1, 42, 53, 52, 43] the target: 10\n",
            "when input is [1] the target: 39\n",
            "when input is [1, 39] the target: 61\n",
            "when input is [1, 39, 61] the target: 39\n",
            "when input is [1, 39, 61, 39] the target: 63\n",
            "when input is [1, 39, 61, 39, 63] the target: 6\n",
            "when input is [1, 39, 61, 39, 63, 6] the target: 1\n",
            "when input is [1, 39, 61, 39, 63, 6, 1] the target: 39\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39] the target: 61\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61] the target: 39\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39] the target: 63\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63] the target: 2\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63, 2] the target: 0\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63, 2, 0] the target: 0\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63, 2, 0, 0] the target: 31\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63, 2, 0, 0, 31] the target: 43\n",
            "when input is [1, 39, 61, 39, 63, 6, 1, 39, 61, 39, 63, 2, 0, 0, 31, 43] the target: 41\n",
            "when input is [53] the target: 52\n",
            "when input is [53, 52] the target: 42\n",
            "when input is [53, 52, 42] the target: 1\n",
            "when input is [53, 52, 42, 1] the target: 15\n",
            "when input is [53, 52, 42, 1, 15] the target: 47\n",
            "when input is [53, 52, 42, 1, 15, 47] the target: 58\n",
            "when input is [53, 52, 42, 1, 15, 47, 58] the target: 47\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47] the target: 64\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64] the target: 43\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43] the target: 52\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52] the target: 10\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52, 10] the target: 0\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0] the target: 27\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 27] the target: 52\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 27, 52] the target: 43\n",
            "when input is [53, 52, 42, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 27, 52, 43] the target: 1\n",
            "when input is [61] the target: 53\n",
            "when input is [61, 53] the target: 56\n",
            "when input is [61, 53, 56] the target: 42\n",
            "when input is [61, 53, 56, 42] the target: 6\n",
            "when input is [61, 53, 56, 42, 6] the target: 1\n",
            "when input is [61, 53, 56, 42, 6, 1] the target: 45\n",
            "when input is [61, 53, 56, 42, 6, 1, 45] the target: 53\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53] the target: 53\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53] the target: 42\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42] the target: 1\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1] the target: 41\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1, 41] the target: 47\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1, 41, 47] the target: 58\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1, 41, 47, 58] the target: 47\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1, 41, 47, 58, 47] the target: 64\n",
            "when input is [61, 53, 56, 42, 6, 1, 45, 53, 53, 42, 1, 41, 47, 58, 47, 64] the target: 43\n",
            "when input is [52] the target: 57\n",
            "when input is [52, 57] the target: 8\n",
            "when input is [52, 57, 8] the target: 0\n",
            "when input is [52, 57, 8, 0] the target: 0\n",
            "when input is [52, 57, 8, 0, 0] the target: 18\n",
            "when input is [52, 57, 8, 0, 0, 18] the target: 47\n",
            "when input is [52, 57, 8, 0, 0, 18, 47] the target: 56\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56] the target: 57\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57] the target: 58\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58] the target: 1\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58] the target: 47\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47] the target: 64\n",
            "when input is [52, 57, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64] the target: 43\n",
            "when input is [52] the target: 10\n",
            "when input is [52, 10] the target: 0\n",
            "when input is [52, 10, 0] the target: 35\n",
            "when input is [52, 10, 0, 35] the target: 43\n",
            "when input is [52, 10, 0, 35, 43] the target: 1\n",
            "when input is [52, 10, 0, 35, 43, 1] the target: 39\n",
            "when input is [52, 10, 0, 35, 43, 1, 39] the target: 56\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56] the target: 43\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43] the target: 1\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1] the target: 39\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39] the target: 41\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39, 41] the target: 41\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39, 41, 41] the target: 53\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39, 41, 41, 53] the target: 59\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39, 41, 41, 53, 59] the target: 52\n",
            "when input is [52, 10, 0, 35, 43, 1, 39, 56, 43, 1, 39, 41, 41, 53, 59, 52] the target: 58\n",
            "when input is [43] the target: 42\n",
            "when input is [43, 42] the target: 1\n",
            "when input is [43, 42, 1] the target: 54\n",
            "when input is [43, 42, 1, 54] the target: 53\n",
            "when input is [43, 42, 1, 54, 53] the target: 53\n",
            "when input is [43, 42, 1, 54, 53, 53] the target: 56\n",
            "when input is [43, 42, 1, 54, 53, 53, 56] the target: 1\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1] the target: 41\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41] the target: 47\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47] the target: 58\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58] the target: 47\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58, 47] the target: 64\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58, 47, 64] the target: 43\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58, 47, 64, 43] the target: 52\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58, 47, 64, 43, 52] the target: 57\n",
            "when input is [43, 42, 1, 54, 53, 53, 56, 1, 41, 47, 58, 47, 64, 43, 52, 57] the target: 6\n",
            "when input is [1] the target: 58\n",
            "when input is [1, 58] the target: 46\n",
            "when input is [1, 58, 46] the target: 43\n",
            "when input is [1, 58, 46, 43] the target: 1\n",
            "when input is [1, 58, 46, 43, 1] the target: 54\n",
            "when input is [1, 58, 46, 43, 1, 54] the target: 39\n",
            "when input is [1, 58, 46, 43, 1, 54, 39] the target: 58\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58] the target: 56\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56] the target: 47\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47] the target: 41\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41] the target: 47\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41, 47] the target: 39\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41, 47, 39] the target: 52\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41, 47, 39, 52] the target: 57\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41, 47, 39, 52, 57] the target: 1\n",
            "when input is [1, 58, 46, 43, 1, 54, 39, 58, 56, 47, 41, 47, 39, 52, 57, 1] the target: 45\n",
            "when input is [53] the target: 53\n",
            "when input is [53, 53] the target: 42\n",
            "when input is [53, 53, 42] the target: 8\n",
            "when input is [53, 53, 42, 8] the target: 0\n",
            "when input is [53, 53, 42, 8, 0] the target: 35\n",
            "when input is [53, 53, 42, 8, 0, 35] the target: 46\n",
            "when input is [53, 53, 42, 8, 0, 35, 46] the target: 39\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39] the target: 58\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58] the target: 1\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1] the target: 39\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39] the target: 59\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39, 59] the target: 58\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39, 59, 58] the target: 46\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39, 59, 58, 46] the target: 53\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39, 59, 58, 46, 53] the target: 56\n",
            "when input is [53, 53, 42, 8, 0, 35, 46, 39, 58, 1, 39, 59, 58, 46, 53, 56] the target: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "TYcDwpPDJn52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "class SingleHeadAttention(nn.Module):\n",
        "  \"\"\"Implements a simple SingleHeadAttention layer for a single example from batch.\"\"\"\n",
        "\n",
        "  head_size: int\n",
        "  num_tokens: int\n",
        "  dropout_rate: float = 0.2\n",
        "  use_causal_mask: bool = True  # if True, only attend to past tokens.\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, tokens: jnp.array, training: bool):\n",
        "    \"\"\"Tokens, each with some channel dim.\"\"\"\n",
        "    # Use separate single dense layers for calculating keys, query, values\n",
        "    keys = nn.Dense(self.head_size, use_bias=False)(tokens)\n",
        "    queries = nn.Dense(self.head_size, use_bias=False)(tokens)\n",
        "    values = nn.Dense(self.head_size, use_bias=False)(tokens)\n",
        "\n",
        "    mask = (\n",
        "        jnp.tril(jnp.ones(shape=(self.num_tokens, self.num_tokens)))\n",
        "        if self.use_causal_mask\n",
        "        else jnp.ones(shape=(self.num_tokens, self.num_tokens))\n",
        "    )\n",
        "\n",
        "    # compute attention score.\n",
        "    # import pdb; pdb.set_trace()\n",
        "    wei = jnp.dot(queries, keys.T) / jnp.sqrt(self.head_size)\n",
        "    wei = jnp.where(mask == 0, -jnp.inf, wei)\n",
        "    wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "    attention_values = jnp.dot(\n",
        "        wei, values\n",
        "    )  # (num_tokens, num_tokens) * (num_tokens, head_size)\n",
        "    attention_values = nn.Dropout(rate=self.dropout_rate, deterministic=True)(\n",
        "        attention_values\n",
        "    )\n",
        "    return attention_values  # (num_tokens, head_size)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"Implements a MultiHeadAttention layer for a single example from batch.\"\"\"\n",
        "\n",
        "  head_size: int\n",
        "  num_heads: int\n",
        "  num_tokens: int\n",
        "  dropout_rate: float = 0.2\n",
        "\n",
        "  def setup(self):\n",
        "    self.heads = [\n",
        "        SingleHeadAttention(\n",
        "            head_size=self.head_size, num_tokens=self.num_tokens\n",
        "        )\n",
        "        for _ in range(self.num_heads)\n",
        "    ]\n",
        "\n",
        "    # Project concatenated output from all attention heads to final output\n",
        "    # dimension, which is head_size * num_heads.\n",
        "    self.projection = nn.Dense(features=self.num_heads * self.head_size)\n",
        "    self.dropout = nn.Dropout(rate=self.dropout_rate, deterministic=True)\n",
        "\n",
        "  def __call__(self, tokens: jnp.array, training: bool):\n",
        "    output_from_each_head = []\n",
        "    for h in self.heads:\n",
        "      head_output = h(tokens, training)\n",
        "      output_from_each_head.append(head_output)\n",
        "\n",
        "    # Run multiple attention heads in parallel and concatenate\n",
        "    # their output along channel dimension, i.e., dim==-1\n",
        "    out_from_all_heads = jnp.concatenate(output_from_each_head, axis=-1)\n",
        "\n",
        "    projection = self.projection(out_from_all_heads)\n",
        "    return self.dropout(projection)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  output_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    # Attention paper uses 4 times token_info_size when doing linear transformation\n",
        "    # and then projects it back to token_info_size in linear transformation layer.\n",
        "    self.ffwd = nn.Dense(features=4 * self.output_size)\n",
        "    self.projection = nn.Dense(self.output_size)\n",
        "\n",
        "  def __call__(self, x, training: bool):\n",
        "    x = nn.relu(self.ffwd(x))\n",
        "    x = self.projection(x)\n",
        "    return x\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "  num_heads: int\n",
        "  # output_size = head_size * num_heads, is the final embedding dimension you get after concatenating from all heads.\n",
        "  output_size: int\n",
        "  num_tokens: int\n",
        "\n",
        "  def setup(self):\n",
        "    # communication.\n",
        "    # each single head will produce head_size worth of info for key, value, querie. You concatenate all of them to get the final output_size.\n",
        "    self.head_size = self.output_size // self.num_heads\n",
        "    self.self_attention_heads = MultiHeadAttention(num_heads=self.num_heads,\n",
        "                                                   head_size = self.head_size,\n",
        "                                                   num_tokens=self.num_tokens)\n",
        "\n",
        "    # computation.\n",
        "    self.computation_layer = FeedForward(output_size=self.output_size)\n",
        "\n",
        "    self.ln1 = nn.LayerNorm()\n",
        "    self.ln2 = nn.LayerNorm()\n",
        "\n",
        "    self.dropout = nn.Dropout(rate=0.2, deterministic=True)\n",
        "\n",
        "  def __call__(self, x, training: bool):\n",
        "    # transformer encoder forward pass\n",
        "    x = x + self.self_attention_heads(self.ln1(x), training)\n",
        "\n",
        "    x = x + self.computation_layer(self.ln2(x), training)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    return x\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "  num_tokens: int # block size, i.e., number of tokens attention block is looking at once\n",
        "  num_heads: int\n",
        "  num_layers: int\n",
        "\n",
        "  def setup(self):\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.num_tokens, features=self.n_embed)\n",
        "\n",
        "    # Since, there are 4 heads, each head only needs to output token_info of size 8.\n",
        "    # Concantenate token_info from all 4 heards, gives us 32\n",
        "    self.blocks = [\n",
        "        TransformerEncoderBlock(num_heads=self.num_heads,\n",
        "                                output_size=self.n_embed,\n",
        "                                num_tokens=self.num_tokens) for _ in range(self.num_layers)\n",
        "    ]\n",
        "    self.ln = nn.LayerNorm()\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array, training: bool):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "    # generate emb for each token. output: (num_tokens, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    # feed x into self-attention head.\n",
        "    # language model, forward pass, block_of_tokens\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.blocks[i](x, training)\n",
        "\n",
        "    x = self.ln(x)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n",
        "\n",
        "    return token_logits\n",
        "\n",
        "\n",
        "class LanguageModelBatch(nn.Module):\n",
        "  \"\"\"Extends MultiHeadAttention to work on a batch of data.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "  num_tokens: int # block size, i.e., number of tokens attention block is looking at once\n",
        "  num_heads: int\n",
        "  num_layers: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.lm_single_example = LanguageModel(\n",
        "        vocab_size=self.vocab_size,\n",
        "        n_embed=self.n_embed,\n",
        "        num_tokens=self.num_tokens,\n",
        "        num_heads=self.num_heads,\n",
        "        num_layers=self.num_layers)\n",
        "\n",
        "    self.lm_batch = jax.vmap(\n",
        "        self.lm_single_example,\n",
        "        in_axes=(0, None),  # tokens, training\n",
        "        out_axes=(0),\n",
        "    )\n",
        "\n",
        "  def __call__(self, tokens: jnp.array, training: bool):\n",
        "    return self.lm_batch(tokens, training)"
      ],
      "metadata": {
        "id": "T-EplD3kJspx"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModelBatch(vocab_size=65,\n",
        "                      n_embed=256,\n",
        "                      num_tokens=BLOCK_SIZE,\n",
        "                      num_heads=2,\n",
        "                      num_layers=1)"
      ],
      "metadata": {
        "id": "J8yhi01bUR5z"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = get_batch(train_dataset)\n",
        "inputs.shape, targets.shape"
      ],
      "metadata": {
        "id": "GSTEXCxNU5Q7",
        "outputId": "8b1aa31d-17b7-4591-f1f4-cfefbf1aa621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 16), (32, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, params = model.init_with_output(jax.random.PRNGKey(99), inputs, training=False)\n",
        "params = params[\"params\"]\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "id": "C-OSerO_VOoZ",
        "outputId": "1d9d86cb-b90e-4d19-bde3-00423309563a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 16, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "id": "yVt_FF2PceE_",
        "outputId": "ba7a731a-98e9-4c6b-824d-d7dfc5e0eac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class TrainState(train_state.TrainState):\n",
        "\n",
        "\n",
        "T = BLOCK_SIZE\n",
        "\n",
        "model = LanguageModelBatch(vocab_size=65,\n",
        "                      n_embed=256,\n",
        "                      num_tokens=BLOCK_SIZE,\n",
        "                      num_heads=2,\n",
        "                      num_layers=1)\n",
        "\n",
        "\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), inputs, training=False)\n",
        "params = params[\"params\"]\n",
        "\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn(params, inputs, False)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "\n",
        "opt = optax.adam(learning_rate=0.0001)\n",
        "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=opt)\n",
        "\n",
        "for epoch in range(1):\n",
        "  batch = get_batch(train_dataset)\n",
        "\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  print(\"loss\", loss, \"epoch\", epoch) if epoch%100==0 else None\n",
        "  state = state.apply_gradients(grads=grads)\n",
        ""
      ],
      "metadata": {
        "id": "Mdnn4TP8cPlX",
        "outputId": "081a08dc-bacc-4d3b-dcd6-b95152b7ac9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ScopeCollectionNotFound",
          "evalue": "Tried to access \"embedding\" from collection \"params\" in \"/lm_single_example/token_embedding_table\" but the collection is empty. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeCollectionNotFound)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mScopeCollectionNotFound\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-67a8f7072557>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-67a8f7072557>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(params, state, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_integer_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-4af359ae698d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tokens, training)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-4af359ae698d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, block_of_tokens, training)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;34m\"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# generate emb for each token. output: (num_tokens, n_embed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtoken_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_embedding_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_of_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# generate position embs for each token.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/linen/linear.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m     self.embedding = self.param('embedding',\n\u001b[0m\u001b[1;32m    756\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mparam\u001b[0;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mutable_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_collection_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopeCollectionNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopeParamNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mScopeCollectionNotFound\u001b[0m: Tried to access \"embedding\" from collection \"params\" in \"/lm_single_example/token_embedding_table\" but the collection is empty. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeCollectionNotFound)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import chex\n",
        "from chex._src import fake\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "from dataclasses import dataclass\n",
        "import importlib\n",
        "import pdb\n",
        "\n",
        "# import dataset\n",
        "# import model\n",
        "\n",
        "class TrainState(train_state.TrainState):\n",
        "    key: jax.random.KeyArray\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    BATCH_SIZE: int = 256\n",
        "    BLOCK_SIZE: int = 64\n",
        "    T: int = 64\n",
        "    n_embed: int = 256\n",
        "    num_heads: int = 8\n",
        "    num_layers: int = 6\n",
        "\n",
        "config = Config()\n",
        "\n",
        "random_key = jax.random.PRNGKey(99)\n",
        "\n",
        "# Initialize model\n",
        "lm_model = LanguageModelBatch(vocab_size=65,\n",
        "                      n_embed=config.n_embed,\n",
        "                      num_tokens=config.BLOCK_SIZE,\n",
        "                      num_heads=config.num_heads,\n",
        "                      num_layers=config.num_layers)\n",
        "\n",
        "output, params = lm_model.init_with_output(jax.random.PRNGKey(99), inputs, training=True)\n",
        "params = params[\"params\"]\n",
        "\n",
        "PER_HOST_BATCH_SIZE = config.BATCH_SIZE // jax.device_count()\n",
        "\n",
        "# Define forward pass\n",
        "def forward_pass(params, state, batch): #, dropout_key):\n",
        "    inputs, targets = batch\n",
        "    logits = state.apply_fn(params, inputs, True)# , dropout_key)\n",
        "\n",
        "    chex.assert_shape(inputs, (PER_HOST_BATCH_SIZE, config.BLOCK_SIZE))\n",
        "    chex.assert_shape(targets, (PER_HOST_BATCH_SIZE, config.BLOCK_SIZE))\n",
        "\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "# Define training step\n",
        "def train_step(state, inputs, targets): #, dropout_key):\n",
        "    # dropout_key = jax.random.fold_in(key=dropout_key, data=state.step)\n",
        "    batch = inputs, targets\n",
        "\n",
        "    grad_fn = jax.value_and_grad(forward_pass, argnums=(0))\n",
        "    loss, grads = grad_fn(state.params, state, batch) # , dropout_key)\n",
        "\n",
        "    loss = jax.lax.pmean(loss, axis_name=\"devices\")\n",
        "    grads = jax.lax.pmean(grads, axis_name=\"devices\")\n",
        "\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    return state, loss\n",
        "\n",
        "# Initialize optimizer and training state\n",
        "opt = optax.adam(learning_rate=0.0001)\n",
        "state = TrainState.create(apply_fn=lm_model.apply, params=params, tx=opt, key=random_key)\n",
        "\n",
        "# pmap the train_step.\n",
        "train_step_pmap = jax.jit(jax.pmap(train_step, in_axes=(0, 0, 0), out_axes=(0), axis_name=\"devices\"))\n",
        "states = jax.device_put_replicated(state, jax.local_devices())"
      ],
      "metadata": {
        "id": "88FqbWNaN5H6",
        "outputId": "46ac4f36-d303-414b-e365-441775165e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Incompatible shapes for broadcasting: shapes=[(4, 16, 256), (4, 256)]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_broadcast_shapes_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_shapes_uncached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    162\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Incompatible shapes for broadcasting: shapes={list(shapes)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(4, 16, 256), (4, 256)]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-8f95ac9e6349>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                       num_layers=config.num_layers)\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_with_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-4af359ae698d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tokens, training)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-4af359ae698d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, block_of_tokens, training)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# generate actual input to attention, x, which is sum of token_embs + pos_embs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# feed x into self-attention head.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4934\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mswap\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accepted_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4936\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rejected_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4938\u001b[0m       raise TypeError(f\"unsupported operand type(s) for {opchar}: \"\n",
            "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/ufuncs.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     95\u001b[0m     lax_doc: bool = False) -> BinOp:\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool_lax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"jax.numpy.{numpy_fn.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_promote_args\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[0m_check_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m   \u001b[0m_check_no_float0s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_promote_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_promote_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_promote_shapes\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_numpy_rank_promotion\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"allow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m           \u001b[0m_rank_promotion_warning_or_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mresult_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         return [_broadcast_to(arg, (1,) * (result_rank - len(shp)) + shp)\n\u001b[1;32m    260\u001b[0m                 for arg, shp in zip(args, shapes)]\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mresult_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_broadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Incompatible shapes for broadcasting: shapes={list(shapes)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(4, 16, 256), (4, 256)]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fake_pmap = chex.fake_pmap_and_jit(enable_jit_patching=fake_jit, enable_pmap_patching=fake_pmap)\n",
        "# fake_pmap.start()\n",
        "num_epochs = 1 # 20\n",
        "steps_per_epoch = 1 # len(data.train_data) // config.BATCH_SIZE\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"epoch: \", epoch)\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    random_key, random_subkey = jax.random.split(random_key)\n",
        "\n",
        "    inputs, targets = get_batch(train_dataset)\n",
        "\n",
        "    # create device dimension for minibatch\n",
        "    inputs = inputs.reshape((jax.device_count(), -1, inputs.shape[-1]))\n",
        "    targets = targets.reshape((jax.device_count(), -1, targets.shape[-1]))\n",
        "\n",
        "    states, loss = train_step_pmap(states, inputs, targets)\n",
        "    print(\"loss\", loss[0], \"epoch\", epoch) if epoch % 1 == 0 else None\n",
        "\n",
        "# fake_pmap.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "siy-deXXO_C3",
        "outputId": "1fd01b69-df4f-4337-a6f0-dcc237c5a243"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_step_pmap' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-321e1a064191>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_step_pmap' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = get_batch(train_dataset)"
      ],
      "metadata": {
        "id": "DwL37mOrUGNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape, targets.shape"
      ],
      "metadata": {
        "id": "FCh53CyIUeh6",
        "outputId": "5b5c4187-675f-454d-f1e2-bd972ef3642b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 16), (32, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create device dimension for minibatch\n",
        "inputs = inputs.reshape((jax.device_count(), -1, inputs.shape[-1]))\n",
        "targets = targets.reshape((jax.device_count(), -1, targets.shape[-1]))# create device dimension for minibatch"
      ],
      "metadata": {
        "id": "3vHU3TE0Ud-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape, targets.shape"
      ],
      "metadata": {
        "id": "dDZXx1i7ULFF",
        "outputId": "6c9373ff-27c6-408a-8f65-9494722ec16b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 4, 16), (8, 4, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}