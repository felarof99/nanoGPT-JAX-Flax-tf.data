{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zRBSLy46lIY",
        "outputId": "b6e6778e-424c-4a2e-8ee1-8a8d360e9c53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()\n",
        "jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a6c43b-195c-4d50-c513-320ef889ac15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "04992d44-b843-4cd2-a892-539d508e98cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHFANuKyilVM",
        "outputId": "934699d9-4b67-47c8-cd45-5247f431002a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  dataset.py  model.py                   nanoGPT_singe_file.ipynb  README.md\n",
            "\u001b[01;34mdata\u001b[0m/    LICENSE     nanoGPT_JAX_JAX_JAX.ipynb  nanoGPT_train.ipynb       trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "import dataset\n",
        "import model\n",
        "\n",
        "importlib.reload(dataset)\n",
        "importlib.reload(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Lwn46KOkxx",
        "outputId": "ca1144a8-61dc-4a3e-d360-923292ce9c20"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'model' from '/content/nanoGPT-JAX-JAX-JAX/model.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import chex\n",
        "from chex._src import fake\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "from dataclasses import dataclass\n",
        "import importlib\n",
        "import pdb\n",
        "\n",
        "# import dataset\n",
        "# import model\n",
        "\n",
        "class TrainState(train_state.TrainState):\n",
        "    key: jax.random.KeyArray\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    BATCH_SIZE: int = 256\n",
        "    BLOCK_SIZE: int = 64\n",
        "    T: int = 64\n",
        "    n_embed: int = 256\n",
        "    num_heads: int = 8\n",
        "    num_layers: int = 6\n",
        "\n",
        "config = Config()\n",
        "\n",
        "random_key = jax.random.PRNGKey(99)\n",
        "\n",
        "# Initialize model\n",
        "lm_model = model.LanguageModel(vocab_size=65,\n",
        "                      n_embed=config.n_embed,\n",
        "                      T=config.BLOCK_SIZE,\n",
        "                      num_heads=config.num_heads,\n",
        "                      num_layers=config.num_layers)\n",
        "sample_block_of_tokens = jnp.ones(shape=(config.T,), dtype=jnp.int32)\n",
        "output, params = lm_model.init_with_output(jax.random.PRNGKey(99), sample_block_of_tokens, training=False)\n",
        "params = params[\"params\"]\n",
        "\n",
        "def model_apply(params, inputs, training, dropout_key):\n",
        "    return lm_model.apply({\"params\": params}, inputs, training, rngs={'dropout': dropout_key})\n",
        "\n",
        "# Vectorize model apply function\n",
        "model_apply_batch = jax.vmap(model_apply, in_axes=(None, 0, None, None), out_axes=(0))\n",
        "\n",
        "PER_HOST_BATCH_SIZE = config.BATCH_SIZE // jax.device_count()\n",
        "\n",
        "# Define forward pass\n",
        "def forward_pass(params, state, batch, dropout_key):\n",
        "    inputs, targets = batch\n",
        "    logits = state.apply_fn(params, inputs, True, dropout_key)\n",
        "\n",
        "    chex.assert_shape(inputs, (PER_HOST_BATCH_SIZE, config.BLOCK_SIZE))\n",
        "    chex.assert_shape(targets, (PER_HOST_BATCH_SIZE, config.BLOCK_SIZE))\n",
        "\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "# Define training step\n",
        "def train_step(state, inputs, targets, dropout_key):\n",
        "    dropout_key = jax.random.fold_in(key=dropout_key, data=state.step)\n",
        "\n",
        "    batch = inputs, targets\n",
        "\n",
        "    grad_fn = jax.value_and_grad(forward_pass, argnums=(0))\n",
        "    loss, grads = grad_fn(state.params, state, batch, dropout_key)\n",
        "\n",
        "    loss = jax.lax.pmean(loss, axis_name=\"devices\")\n",
        "    grads = jax.lax.pmean(grads, axis_name=\"devices\")\n",
        "\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    return state, loss\n",
        "\n",
        "# Initialize optimizer and training state\n",
        "opt = optax.adam(learning_rate=0.0001)\n",
        "state = TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt, key=random_key)\n",
        "data = dataset.Dataset(batch_size=config.BATCH_SIZE, block_size=config.BLOCK_SIZE)\n",
        "\n",
        "# pmap the train_step.\n",
        "train_step_pmap = jax.jit(jax.pmap(train_step, in_axes=(0, 0, 0, None), out_axes=(0), axis_name=\"devices\"))\n",
        "states = jax.device_put_replicated(state, jax.local_devices())\n",
        "\n"
      ],
      "metadata": {
        "id": "92Md4ebTBeET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run a training step\n",
        "# This is an **IMPURE function** for convenience. Don't JIT it.\n",
        "reload_libs = False\n",
        "if reload_libs:\n",
        "  importlib.reload(dataset)\n",
        "  importlib.reload(model)\n",
        "\n",
        "\n",
        "# fake_pmap = chex.fake_pmap_and_jit(enable_jit_patching=fake_jit, enable_pmap_patching=fake_pmap)\n",
        "# fake_pmap.start()\n",
        "num_epochs = 1 # 20\n",
        "steps_per_epoch = 1 # len(data.train_data) // config.BATCH_SIZE\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"epoch: \", epoch)\n",
        "  data.create_train_dataset()\n",
        "\n",
        "  for step in range(steps_per_epoch):\n",
        "    random_key, random_subkey = jax.random.split(random_key)\n",
        "\n",
        "    inputs, targets = data.get_batch()\n",
        "\n",
        "    # create device dimension for minibatch\n",
        "    inputs = inputs.reshape((jax.device_count(), -1, inputs.shape[-1]))\n",
        "    targets = targets.reshape((jax.device_count(), -1, targets.shape[-1]))\n",
        "\n",
        "    states, loss = train_step_pmap(states, inputs, targets, random_subkey)\n",
        "    print(\"loss\", loss[0], \"epoch\", epoch) if epoch % 510 == 0 else None\n",
        "\n",
        "# fake_pmap.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MVQEgvzBhFD",
        "outputId": "17bc4652-ac6d-4c9d-fd31-48fb2d01652a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n",
            "loss 3.9624007 epoch 0\n",
            "loss 3.88149 epoch 0\n",
            "loss 3.8095543 epoch 0\n",
            "loss 3.7548494 epoch 0\n",
            "loss 3.7914453 epoch 0\n",
            "loss 3.7002654 epoch 0\n",
            "loss 3.6340194 epoch 0\n",
            "loss 3.6558213 epoch 0\n",
            "loss 3.6011715 epoch 0\n",
            "loss 3.61494 epoch 0\n",
            "loss 3.6759403 epoch 0\n",
            "loss 3.595214 epoch 0\n",
            "loss 3.6045206 epoch 0\n",
            "loss 3.6529965 epoch 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T = config.BLOCK_SIZE\n",
        "\n",
        "state = jax.tree_map(lambda x: x[0], states)\n",
        "\n",
        "state_apply_jit = jax.jit(state.apply_fn)\n",
        "\n",
        "context = jnp.tile(jnp.array([52], dtype=jnp.int32), T)\n",
        "context = context[None, -T:]\n",
        "key = jrand.PRNGKey(99)\n",
        "\n",
        "for _ in range(100):\n",
        "  next_token_logits = state_apply_jit({\"params\": state.params}, context[:, -T:])\n",
        "\n",
        "  key, split_key = jrand.split(key)\n",
        "  new_token = jax.random.categorical(key, next_token_logits[:, -1, :], axis=-1, shape=(1, 1))\n",
        "\n",
        "  context = jnp.concatenate([context, new_token], axis=1)\n",
        "\n",
        "\n",
        "print(context.tolist()[0])"
      ],
      "metadata": {
        "id": "Gmoj-CS-JDol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}