{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Use CPU runtime"
      ],
      "metadata": {
        "id": "16WhNG98gurS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6427RRkAbysU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a104433-163f-4ed1-f857-6f32fd7afd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-11 01:34:41--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-11-11 01:34:41 (14.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "!pip install -q --upgrade pip # To support manylinux2010 wheels.\n",
        "!pip install -q --upgrade jax jaxlib # CPU-only\n",
        "!pip install -q --upgrade jaxtyping\n",
        "!pip install -q --upgrade flax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import jaxtyping\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "OZqEXlfmfuwo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset pipeline"
      ],
      "metadata": {
        "id": "TeccUW1zg-V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Create chars vocubulary using all the unique characters in the text.\n",
        "chars = sorted(list(set(text)))\n",
        "VOCAB_SIZE = len(chars)\n",
        "\n",
        "# Create mapping from characters to integers.\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create reverse mapping from integers to characters.\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create encode, decode function.\n",
        "def encode(s: str, stoi: Mapping[str, int]) -> List[int]:\n",
        "  return [stoi[c] for c in s]\n",
        "\n",
        "def decode(tokens: List[int], itos: Mapping[int, str]) -> str:\n",
        "  return ''.join([itos[i] for i in tokens])\n",
        "\n",
        "println(encode(\"hii there\", stoi), decode(encode(\"hii there\", stoi), itos))\n",
        "\n",
        "# Let's now split up the data into train and validation sets.\n",
        "data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# Below would result in a minibatch size of 32.\n",
        "BATCH_SIZE = 4 # how many independent sequences will we process in parallel?\n",
        "BLOCK_SIZE = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "val_dataset = (tf.data.Dataset.from_tensor_slices(val_data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "\n",
        "def get_batch(training: bool = True):\n",
        "  if not training:\n",
        "    val_batch = next(val_dataset)\n",
        "    return jnp.array(val_batch)\n",
        "\n",
        "  train_batch = next(train_dataset)\n",
        "  return jnp.array(train_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYycQ8ocg2sy",
        "outputId": "0517c8b9-f910-421d-f62b-0621c4fc0c67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-560c18dc3230>:24: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch()\n",
        "println(\"inputs\", xb, \"inputs shape\", xb.shape)\n",
        "println(\"targets\", yb, \"targets shape\", yb.shape)\n",
        "for b in range(BATCH_SIZE): # batch dimension\n",
        "    for t in range(BLOCK_SIZE): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YTqHDylg6cY",
        "outputId": "35744482-a132-4f1f-97bd-6afa95c082b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[18 47 56 57 58  1 15 47]\n",
            " [47 64 43 52 10  0 14 43]\n",
            " [53 56 43  1 61 43  1 54]\n",
            " [53 41 43 43 42  1 39 52]]\n",
            "inputs shape\n",
            "(4, 8)\n",
            "targets\n",
            "[[47 56 57 58  1 15 47 58]\n",
            " [64 43 52 10  0 14 43 44]\n",
            " [56 43  1 61 43  1 54 56]\n",
            " [41 43 43 42  1 39 52 63]]\n",
            "targets shape\n",
            "(4, 8)\n",
            "when input is [18] the target: 47\n",
            "when input is [18, 47] the target: 56\n",
            "when input is [18, 47, 56] the target: 57\n",
            "when input is [18, 47, 56, 57] the target: 58\n",
            "when input is [18, 47, 56, 57, 58] the target: 1\n",
            "when input is [18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [47] the target: 64\n",
            "when input is [47, 64] the target: 43\n",
            "when input is [47, 64, 43] the target: 52\n",
            "when input is [47, 64, 43, 52] the target: 10\n",
            "when input is [47, 64, 43, 52, 10] the target: 0\n",
            "when input is [47, 64, 43, 52, 10, 0] the target: 14\n",
            "when input is [47, 64, 43, 52, 10, 0, 14] the target: 43\n",
            "when input is [47, 64, 43, 52, 10, 0, 14, 43] the target: 44\n",
            "when input is [53] the target: 56\n",
            "when input is [53, 56] the target: 43\n",
            "when input is [53, 56, 43] the target: 1\n",
            "when input is [53, 56, 43, 1] the target: 61\n",
            "when input is [53, 56, 43, 1, 61] the target: 43\n",
            "when input is [53, 56, 43, 1, 61, 43] the target: 1\n",
            "when input is [53, 56, 43, 1, 61, 43, 1] the target: 54\n",
            "when input is [53, 56, 43, 1, 61, 43, 1, 54] the target: 56\n",
            "when input is [53] the target: 41\n",
            "when input is [53, 41] the target: 43\n",
            "when input is [53, 41, 43] the target: 43\n",
            "when input is [53, 41, 43, 43] the target: 42\n",
            "when input is [53, 41, 43, 43, 42] the target: 1\n",
            "when input is [53, 41, 43, 43, 42, 1] the target: 39\n",
            "when input is [53, 41, 43, 43, 42, 1, 39] the target: 52\n",
            "when input is [53, 41, 43, 43, 42, 1, 39, 52] the target: 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLangModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.vocab_size)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    # Run block size inputs through embedding lookup.\n",
        "    # For each char, you get the logit predicted for that char.\n",
        "    # Then, you use the target token for that input and do a cross_entropy_loss.\n",
        "    logits = self.token_embedding_table(inputs)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "2eyyiNsw_YL-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In flax, you need to init the model with sample input that you would pass during each forward pass.\n",
        "sample_input_row = jrand.randint(key=jrand.PRNGKey(99), minval=0, maxval=65, dtype=jnp.int32, shape=[BLOCK_SIZE])\n",
        "sample_input_row"
      ],
      "metadata": {
        "id": "cKYsKCciBBqc",
        "outputId": "408cc95a-4df4-4a87-9c6b-7427c5ec9ae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([21, 23, 50, 28, 53, 55, 40, 29], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input_batch = jrand.randint(key=jrand.PRNGKey(99), minval=0, maxval=65, dtype=jnp.int32, shape=[BATCH_SIZE, BLOCK_SIZE])\n",
        "sample_input_batch"
      ],
      "metadata": {
        "id": "-26e9X59CWas",
        "outputId": "58b9d659-83d3-42a9-b18e-a5a08a154c0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[52,  4, 61, 62, 37, 37, 33, 18],\n",
              "       [64, 41, 20,  2, 41, 35, 29, 21],\n",
              "       [40, 45, 52, 10, 12, 55, 49, 56],\n",
              "       [ 3, 60, 15,  5, 14, 12,  1, 13]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLangModel(vocab_size=65)\n",
        "params = model.init(jrand.PRNGKey(99), sample_input_batch)[\"params\"]\n",
        "model, params"
      ],
      "metadata": {
        "id": "dtb3A3KFCgF8",
        "outputId": "b333295c-00f1-4ccd-b94e-5348c54a0687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(BigramLangModel(\n",
              "     # attributes\n",
              "     vocab_size = 65\n",
              " ),\n",
              " {'token_embedding_table': {'embedding': Array([[ 0.0752212 ,  0.01071652, -0.02585994, ..., -0.06997449,\n",
              "            0.10274917, -0.0226865 ],\n",
              "          [ 0.09400459,  0.12404279,  0.06972364, ...,  0.0593865 ,\n",
              "            0.1517611 ,  0.11131446],\n",
              "          [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
              "            0.01281604,  0.03134193],\n",
              "          ...,\n",
              "          [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
              "            0.11875169, -0.08573762],\n",
              "          [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
              "           -0.02818088,  0.13305528],\n",
              "          [-0.12428083, -0.13785616, -0.12170235, ..., -0.07394623,\n",
              "            0.19811267, -0.06473607]], dtype=float32)}})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_logits = model.apply({\"params\": params}, sample_input_batch)\n",
        "\"sample batch shape\", sample_input_batch.shape, \"sample logits\", sample_logits"
      ],
      "metadata": {
        "id": "AOqPQ3R7Cqab",
        "outputId": "1ba97266-466e-4e36-ddb5-579b74fb4cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sample batch shape',\n",
              " (4, 8),\n",
              " 'sample logits',\n",
              " Array([[[ 8.75270739e-02, -2.27933563e-02,  2.42999336e-03, ...,\n",
              "           1.76198840e-01, -2.76548654e-01,  4.57528904e-02],\n",
              "         [ 1.04733538e-02,  3.02993655e-01, -6.49068654e-02, ...,\n",
              "          -3.16001356e-01,  6.11841679e-02,  4.50519659e-02],\n",
              "         [-3.75676826e-02,  2.13820398e-01,  5.01289777e-02, ...,\n",
              "          -4.57006246e-02, -4.29858230e-02, -2.51459748e-01],\n",
              "         ...,\n",
              "         [ 3.42681557e-02, -5.03289811e-02,  6.59156889e-02, ...,\n",
              "          -8.72746203e-03,  4.07012515e-02,  3.04256212e-02],\n",
              "         [-2.42578298e-01, -9.27777663e-02,  3.04300897e-02, ...,\n",
              "          -7.17728958e-02,  4.83715236e-02, -5.26186675e-02],\n",
              "         [-5.26097491e-02, -6.47737905e-02,  2.42933154e-01, ...,\n",
              "           1.00368716e-01,  1.61088228e-01, -2.64439564e-02]],\n",
              " \n",
              "        [[-1.24280833e-01, -1.37856156e-01, -1.21702351e-01, ...,\n",
              "          -7.39462301e-02,  1.98112667e-01, -6.47360682e-02],\n",
              "         [-1.87322591e-02, -8.34008828e-02,  2.66464800e-02, ...,\n",
              "           2.41142814e-04, -1.24305926e-01, -2.14209050e-01],\n",
              "         [ 1.40742183e-01,  4.47804034e-02, -4.97898757e-02, ...,\n",
              "           1.06872633e-01, -1.69863269e-01,  9.63912755e-02],\n",
              "         ...,\n",
              "         [-2.18365900e-02, -1.33408770e-01, -1.61042795e-01, ...,\n",
              "           1.28409058e-01, -2.47944042e-01,  1.21987369e-02],\n",
              "         [ 6.27776459e-02, -1.29092962e-01, -1.31305531e-01, ...,\n",
              "          -1.44186735e-01, -1.72818843e-02,  7.94342235e-02],\n",
              "         [ 1.15937106e-01,  7.76742166e-03,  4.97238934e-02, ...,\n",
              "          -1.08351722e-01, -8.27843100e-02, -1.41089018e-02]],\n",
              " \n",
              "        [[ 9.88690779e-02,  1.10699371e-01,  2.04316109e-01, ...,\n",
              "           5.69931865e-02, -1.29279003e-01,  1.35084927e-01],\n",
              "         [ 1.63454562e-02, -5.56710958e-02,  9.16817263e-02, ...,\n",
              "           6.80316687e-02, -1.71030417e-01, -6.03942238e-02],\n",
              "         [ 8.75270739e-02, -2.27933563e-02,  2.42999336e-03, ...,\n",
              "           1.76198840e-01, -2.76548654e-01,  4.57528904e-02],\n",
              "         ...,\n",
              "         [ 1.23051435e-01, -3.07502151e-02, -3.00151944e-01, ...,\n",
              "          -4.61103059e-02, -5.33775538e-02,  9.72025655e-03],\n",
              "         [-5.11145815e-02, -1.92709029e-01,  1.27516329e-01, ...,\n",
              "           1.12451855e-02, -1.94980115e-01, -8.80732387e-02],\n",
              "         [ 1.14159331e-01,  1.74362347e-01,  2.06307787e-02, ...,\n",
              "          -4.88526076e-02,  1.13502391e-01,  8.36931989e-02]],\n",
              " \n",
              "        [[-1.16519429e-01,  1.18095562e-01,  5.52669130e-02, ...,\n",
              "           7.41938353e-02, -9.06513184e-02, -1.24847330e-01],\n",
              "         [ 3.81252612e-03, -2.20157523e-02, -2.24012539e-01, ...,\n",
              "           1.47580937e-01, -3.39552350e-02,  1.24758910e-02],\n",
              "         [ 1.81900728e-02,  1.11501746e-01, -1.40141115e-01, ...,\n",
              "          -1.08964294e-01, -2.03329674e-03, -3.32458973e-01],\n",
              "         ...,\n",
              "         [ 2.92513948e-02,  7.48720840e-02, -2.44637251e-01, ...,\n",
              "          -1.84457287e-01, -4.74602692e-02, -1.10139936e-01],\n",
              "         [ 9.40045938e-02,  1.24042794e-01,  6.97236434e-02, ...,\n",
              "           5.93864955e-02,  1.51761100e-01,  1.11314461e-01],\n",
              "         [-1.46842197e-01, -1.46077707e-01,  1.41137019e-01, ...,\n",
              "          -4.00555134e-02, -3.87676097e-02, -2.16341056e-02]]],      dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample forward pass, loss and backward pass."
      ],
      "metadata": {
        "id": "BPYIijJYDSV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = get_batch()\n",
        "inputs, targets = batch\n",
        "println(\"inputs\", inputs, inputs.shape, \"targets\", targets.shape)"
      ],
      "metadata": {
        "id": "x9UFVRpPDeZI",
        "outputId": "b1bc636c-a739-4e1e-89cd-345d7f34099b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[ 6  1 57 54 43 39 49  8]\n",
            " [ 0 18 47 56 57 58  1 15]\n",
            " [58 47 64 43 52 10  0 37]\n",
            " [59  1 39 56 43  1 39 50]]\n",
            "(4, 8)\n",
            "targets\n",
            "(4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode a batch containing several input rows.\n",
        "println(\",\".join([decode(input_row, itos) for input_row in inputs.tolist()]))"
      ],
      "metadata": {
        "id": "s1yjp5qdEKMR",
        "outputId": "8381affe-0b15-4e34-f29d-c7e731a16cb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", speak.,\n",
            "First C,tizen:\n",
            "Y,u are al\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.apply({\"params\": params}, inputs)\n",
        "loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "loss = loss.mean()\n",
        "println(loss)"
      ],
      "metadata": {
        "id": "Za7g7vR_FQCQ",
        "outputId": "ce90c9a6-ba7d-48e6-bcf7-c7917bc52a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.188369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To do backward pass, you first need to compute grads.\n",
        "# In JAX, you use jax.grad to do a function transformation on the forward\n",
        "# function to get the gradient of the original function.\n",
        "# The grad is calculate wrt to the first param in the function.\n",
        "def forward_pass(params, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = model.apply({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "09vAczHeGDis"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_fn = jax.grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument."
      ],
      "metadata": {
        "id": "lJnYF1OtGzPq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grads = grad_fn(params, batch)\n",
        "# These are the grads for the params.\n",
        "println(grads)"
      ],
      "metadata": {
        "id": "o3XKCpCJHQip",
        "outputId": "da995726-b4c1-44f1-e066-aedbe12b6700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'token_embedding_table': {'embedding': Array([[0.00103511, 0.00097044, 0.00093559, ..., 0.00089521, 0.001064  ,\n",
            "        0.00093856],\n",
            "       [0.00203619, 0.00209828, 0.00198735, ..., 0.00196691, 0.00215726,\n",
            "        0.00207174],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.00040068, 0.00039527, 0.00040171, ..., 0.00042136, 0.00055311,\n",
            "        0.00042526]], dtype=float32)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply grads to params to get new params.\n",
        "lr = 0.001\n",
        "println(\"params before:\", params)\n",
        "params = jax.tree_map(lambda p, g: p - lr * g, params, grads)\n",
        "println(\"params after:\", params)"
      ],
      "metadata": {
        "id": "qLHB0BpQHfI1",
        "outputId": "82e79e23-aa76-4415-92ae-ad876ff0af18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params before:\n",
            "{'token_embedding_table': {'embedding': Array([[ 0.0752212 ,  0.01071652, -0.02585994, ..., -0.06997449,\n",
            "         0.10274917, -0.0226865 ],\n",
            "       [ 0.09400459,  0.12404279,  0.06972364, ...,  0.0593865 ,\n",
            "         0.1517611 ,  0.11131446],\n",
            "       [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
            "         0.01281604,  0.03134193],\n",
            "       ...,\n",
            "       [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
            "         0.11875169, -0.08573762],\n",
            "       [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
            "        -0.02818088,  0.13305528],\n",
            "       [-0.12428083, -0.13785616, -0.12170235, ..., -0.07394623,\n",
            "         0.19811267, -0.06473607]], dtype=float32)}}\n",
            "params after:\n",
            "{'token_embedding_table': {'embedding': Array([[ 0.07522016,  0.01071555, -0.02586087, ..., -0.06997538,\n",
            "         0.1027481 , -0.02268744],\n",
            "       [ 0.09400256,  0.12404069,  0.06972165, ...,  0.05938453,\n",
            "         0.15175894,  0.11131239],\n",
            "       [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
            "         0.01281604,  0.03134193],\n",
            "       ...,\n",
            "       [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
            "         0.11875169, -0.08573762],\n",
            "       [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
            "        -0.02818088,  0.13305528],\n",
            "       [-0.12428124, -0.13785656, -0.12170275, ..., -0.07394665,\n",
            "         0.19811212, -0.06473649]], dtype=float32)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing train step in flax"
      ],
      "metadata": {
        "id": "LKPwDOFmIaSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs)\n",
        "  # println(logits)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "XTFr_QJgIjE8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_fn = jax.grad(compute_loss, argnums=(0))"
      ],
      "metadata": {
        "id": "oHtnU9jjJf52"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}