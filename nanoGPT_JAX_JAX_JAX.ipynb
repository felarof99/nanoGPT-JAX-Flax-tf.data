{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Install dependencies for CPU</h1>"
      ],
      "metadata": {
        "id": "16WhNG98gurS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6427RRkAbysU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ac34ec5b-cc49-4737-eba4-b45e13ea4574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-04 20:33:00--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-02-04 20:33:01 (32.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q --upgrade pip # To support manylinux2010 wheels.\n",
        "# !pip install -q --upgrade jax jaxlib # CPU-only\n",
        "# !pip install -q --upgrade jaxtyping\n",
        "# !pip install -q --upgrade flax"
      ],
      "metadata": {
        "id": "5qQHP7SGLTlT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "# import jaxtyping\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "OZqEXlfmfuwo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset pipeline"
      ],
      "metadata": {
        "id": "TeccUW1zg-V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Create chars vocubulary using all the unique characters in the text.\n",
        "chars = sorted(list(set(text)))\n",
        "VOCAB_SIZE = len(chars)\n",
        "\n",
        "# Create mapping from characters to integers.\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create reverse mapping from integers to characters.\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create encode, decode function.\n",
        "def encode(s: str, stoi: Mapping[str, int]) -> List[int]:\n",
        "  return [stoi[c] for c in s]\n",
        "\n",
        "def decode(tokens: List[int], itos: Mapping[int, str]) -> str:\n",
        "  return ''.join([itos[i] for i in tokens])\n",
        "\n",
        "println(encode(\"hii there\", stoi), decode(encode(\"hii there\", stoi), itos))\n",
        "\n",
        "# Let's now split up the data into train and validation sets.\n",
        "data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# Below would result in a minibatch size of 32.\n",
        "BATCH_SIZE = 4 # how many independent sequences will we process in parallel?\n",
        "BLOCK_SIZE = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "val_dataset = (tf.data.Dataset.from_tensor_slices(val_data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "\n",
        "def get_batch(training: bool = True):\n",
        "  if not training:\n",
        "    val_batch = next(val_dataset)\n",
        "    return jnp.array(val_batch)\n",
        "\n",
        "  train_batch = next(train_dataset)\n",
        "  return jnp.array(train_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jYycQ8ocg2sy",
        "outputId": "abcf5b47-49bf-4b8c-adc1-96b401e0e3da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-560c18dc3230>:24: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test dataset pipeline"
      ],
      "metadata": {
        "id": "sTAGaeSwXeG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch()\n",
        "println(\"inputs\", xb, \"inputs shape\", xb.shape)\n",
        "println(\"targets\", yb, \"targets shape\", yb.shape)\n",
        "for b in range(BATCH_SIZE): # batch dimension\n",
        "    for t in range(BLOCK_SIZE): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3YTqHDylg6cY",
        "outputId": "d2b8b244-d58d-4f41-ce0a-a63d1bc0f674"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[18 47 56 57 58  1 15 47]\n",
            " [47 64 43 52 10  0 14 43]\n",
            " [53 56 43  1 61 43  1 54]\n",
            " [53 41 43 43 42  1 39 52]]\n",
            "inputs shape\n",
            "(4, 8)\n",
            "targets\n",
            "[[47 56 57 58  1 15 47 58]\n",
            " [64 43 52 10  0 14 43 44]\n",
            " [56 43  1 61 43  1 54 56]\n",
            " [41 43 43 42  1 39 52 63]]\n",
            "targets shape\n",
            "(4, 8)\n",
            "when input is [18] the target: 47\n",
            "when input is [18, 47] the target: 56\n",
            "when input is [18, 47, 56] the target: 57\n",
            "when input is [18, 47, 56, 57] the target: 58\n",
            "when input is [18, 47, 56, 57, 58] the target: 1\n",
            "when input is [18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [47] the target: 64\n",
            "when input is [47, 64] the target: 43\n",
            "when input is [47, 64, 43] the target: 52\n",
            "when input is [47, 64, 43, 52] the target: 10\n",
            "when input is [47, 64, 43, 52, 10] the target: 0\n",
            "when input is [47, 64, 43, 52, 10, 0] the target: 14\n",
            "when input is [47, 64, 43, 52, 10, 0, 14] the target: 43\n",
            "when input is [47, 64, 43, 52, 10, 0, 14, 43] the target: 44\n",
            "when input is [53] the target: 56\n",
            "when input is [53, 56] the target: 43\n",
            "when input is [53, 56, 43] the target: 1\n",
            "when input is [53, 56, 43, 1] the target: 61\n",
            "when input is [53, 56, 43, 1, 61] the target: 43\n",
            "when input is [53, 56, 43, 1, 61, 43] the target: 1\n",
            "when input is [53, 56, 43, 1, 61, 43, 1] the target: 54\n",
            "when input is [53, 56, 43, 1, 61, 43, 1, 54] the target: 56\n",
            "when input is [53] the target: 41\n",
            "when input is [53, 41] the target: 43\n",
            "when input is [53, 41, 43] the target: 43\n",
            "when input is [53, 41, 43, 43] the target: 42\n",
            "when input is [53, 41, 43, 43, 42] the target: 1\n",
            "when input is [53, 41, 43, 43, 42, 1] the target: 39\n",
            "when input is [53, 41, 43, 43, 42, 1, 39] the target: 52\n",
            "when input is [53, 41, 43, 43, 42, 1, 39, 52] the target: 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Bigram Model"
      ],
      "metadata": {
        "id": "a3ozrVm0XiVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLangModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.vocab_size)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    # Run block size inputs through embedding lookup.\n",
        "    # For each char, you get the logit predicted for that char.\n",
        "    # Then, you use the target token for that input and do a cross_entropy_loss.\n",
        "    logits = self.token_embedding_table(inputs)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "2eyyiNsw_YL-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I'll make the flax model accept\n",
        "`[block size worth tokens, token]`\n",
        "\n",
        "## I'll then use vmap to make the model accept batches of data.\n",
        "`[batch dim, block size worth of tokens, token]`"
      ],
      "metadata": {
        "id": "bLZdjG6cVxij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input_row = jnp.ones(shape=[1, 1], dtype=jnp.int32)\n",
        "sample_input_row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FkxBwwipK6Yc",
        "outputId": "db164faf-ea8b-4896-d851-6351c93823be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLangModel(vocab_size=65)\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), sample_input_row)\n",
        "params = params[\"params\"]"
      ],
      "metadata": {
        "id": "dtb3A3KFCgF8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make the model accepts batch of data\n",
        "`[batch, block of tokens, token_ids]`\n",
        "\n",
        "## To make it accept a batch, you need to use vmap."
      ],
      "metadata": {
        "id": "n0GfZYSQRE93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_apply_batch = jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0))"
      ],
      "metadata": {
        "id": "nu8eFbAURSOy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_apply_batch will accept\n",
        "# [batch, block of tokens, token ids]"
      ],
      "metadata": {
        "id": "eHo-zsVlWxNl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample forward pass, loss and backward pass."
      ],
      "metadata": {
        "id": "BPYIijJYDSV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = get_batch()\n",
        "inputs, targets = batch\n",
        "println(\"inputs\", inputs, inputs.shape, \"targets\", targets.shape)"
      ],
      "metadata": {
        "id": "x9UFVRpPDeZI",
        "outputId": "2c23792b-657c-4399-c871-c994949d04bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[ 1 44 59 56 58 46 43 56]\n",
            " [ 1 46 43 39 56  1 51 43]\n",
            " [57 54 43 39 49  8  0  0]\n",
            " [50 50 10  0 31 54 43 39]]\n",
            "(4, 8)\n",
            "targets\n",
            "(4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model_apply_batch({\"params\": params}, inputs)"
      ],
      "metadata": {
        "id": "JNlkzt-IRr5O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output should shape [4, 8, 65]\n",
        "# batch size = 4\n",
        "# block of tokens = 8\n",
        "# token_id to embedding = 65\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EiE6Yl0QXFml",
        "outputId": "f87e447e-3a5d-4be7-d892-32c9820de75e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 8, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To do backward pass, you first need to compute grads.\n",
        "# In JAX, you use jax.grad to do a function transformation on the forward\n",
        "# function to get the gradient of the original function.\n",
        "# The grad is calculate wrt to the first param in the function.\n",
        "def forward_pass(params, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = model_apply_batch({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "09vAczHeGDis"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test forward pass.\n",
        "batch = get_batch()\n",
        "forward_pass(params=params, batch=batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KCh6wzoHYWDm",
        "outputId": "ef5d18c9-ccea-4fcd-a8d0-138c2e835921"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(4.188369, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument."
      ],
      "metadata": {
        "id": "lJnYF1OtGzPq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test forward pass and grads.\n",
        "# Grads would be the gradients for params.\n",
        "loss, grads = grad_fn(params, batch)\n",
        "println(\"loss\", loss, \"grads\", grads)"
      ],
      "metadata": {
        "id": "o3XKCpCJHQip",
        "outputId": "ca04378f-1c87-4495-da0e-b9b79135f94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "4.188369\n",
            "grads\n",
            "{'token_embedding_table': {'embedding': Array([[0.00103511, 0.00097044, 0.00093559, ..., 0.00089521, 0.001064  ,\n",
            "        0.00093856],\n",
            "       [0.00203619, 0.00209828, 0.00198735, ..., 0.00196691, 0.00215726,\n",
            "        0.00207174],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.00040068, 0.00039527, 0.00040171, ..., 0.00042136, 0.00055311,\n",
            "        0.00042526]], dtype=float32)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply grads to params to get new params.\n",
        "lr = 0.001\n",
        "println(\"params before:\", params)\n",
        "params = jax.tree_map(lambda p, g: p - lr * g, params, grads)\n",
        "println(\"params after:\", params)"
      ],
      "metadata": {
        "id": "qLHB0BpQHfI1",
        "outputId": "46a7e247-b918-4e85-d0aa-d0980d90a220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params before:\n",
            "{'token_embedding_table': {'embedding': Array([[ 0.0752212 ,  0.01071652, -0.02585994, ..., -0.06997449,\n",
            "         0.10274917, -0.0226865 ],\n",
            "       [ 0.09400459,  0.12404279,  0.06972364, ...,  0.0593865 ,\n",
            "         0.1517611 ,  0.11131445],\n",
            "       [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
            "         0.01281604,  0.03134193],\n",
            "       ...,\n",
            "       [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
            "         0.1187517 , -0.08573762],\n",
            "       [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
            "        -0.02818088,  0.13305528],\n",
            "       [-0.12428083, -0.13785616, -0.12170236, ..., -0.07394623,\n",
            "         0.19811267, -0.06473607]], dtype=float32)}}\n",
            "params after:\n",
            "{'token_embedding_table': {'embedding': Array([[ 0.07522016,  0.01071555, -0.02586087, ..., -0.06997538,\n",
            "         0.1027481 , -0.02268744],\n",
            "       [ 0.09400256,  0.12404069,  0.06972165, ...,  0.05938453,\n",
            "         0.15175894,  0.11131237],\n",
            "       [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
            "         0.01281604,  0.03134193],\n",
            "       ...,\n",
            "       [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
            "         0.1187517 , -0.08573762],\n",
            "       [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
            "        -0.02818088,  0.13305528],\n",
            "       [-0.12428124, -0.13785656, -0.12170276, ..., -0.07394665,\n",
            "         0.19811212, -0.06473649]], dtype=float32)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing train step in flax\n",
        "## copy-pasting everything at one place and running a train step."
      ],
      "metadata": {
        "id": "LKPwDOFmIaSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLangModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.vocab_size)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    # Run block size inputs through embedding lookup.\n",
        "    # For each char, you get the logit predicted for that char.\n",
        "    # Then, you use the target token for that input and do a cross_entropy_loss.\n",
        "    logits = self.token_embedding_table(inputs)\n",
        "    return logits\n",
        "\n",
        "model = BigramLangModel(vocab_size=65)\n",
        "\n",
        "sample_input_row = jnp.ones(shape=[1, 1], dtype=jnp.int32)\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), sample_input_row)\n",
        "params = params[\"params\"]\n",
        "\n",
        "model_apply_batch = jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0))\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "\n",
        "opt = optax.adam(learning_rate=0.001)\n",
        "state = train_state.TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  batch = get_batch()\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  print(loss) if epoch%100==0 else None\n",
        "  state = state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gtzCS8NzMJx9",
        "outputId": "c4dd142b-7696-4724-a6f6-946bdda05244"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1769814\n",
            "4.093553\n",
            "4.0517178\n",
            "3.9815784\n",
            "3.955411\n",
            "3.8293285\n",
            "3.7160275\n",
            "3.7963347\n",
            "3.7700095\n",
            "3.5433385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement code for generating tokens"
      ],
      "metadata": {
        "id": "Bze9wctCbxls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_token = \"n\"\n",
        "encode(input_token, stoi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h2BUBirGMWo6",
        "outputId": "26a0d344-70ed-450e-b1e3-7669a5d80d14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[52]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token = jnp.array([[52]], dtype=jnp.int32)\n",
        "input_token.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8p4A99r1NKx-",
        "outputId": "ffca67d0-c66f-4b28-802c-78cba3aca38d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logit = state.apply_fn({\"params\": state.params}, input_token)"
      ],
      "metadata": {
        "id": "cJwJPnIlNSEP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Df1oFKh9N4oj",
        "outputId": "d480dc37-5b81-4b86-fcb4-58e89d671285"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[-0.03682718,  0.3873823 , -0.6297037 , -0.49402413,\n",
              "         -0.5302313 , -0.06883954,  0.02130109, -0.38699383,\n",
              "          0.05293135, -0.67822653,  0.04108686, -0.17033677,\n",
              "         -0.21989107, -0.664077  , -0.5178356 , -0.8944765 ,\n",
              "         -0.47879392, -0.6437434 , -0.8325122 , -0.8247406 ,\n",
              "         -0.7639986 , -0.6349938 , -0.5891391 , -0.71123016,\n",
              "         -0.6316706 , -0.8322299 , -0.61255544, -0.8065904 ,\n",
              "         -0.6916736 , -0.7578409 , -0.77268964, -0.66586775,\n",
              "         -0.48679668, -0.6974697 , -0.5410919 , -0.86016047,\n",
              "         -0.7141595 , -0.87438166, -0.67868704,  0.03718114,\n",
              "         -0.9563432 , -0.07171286,  0.3103663 ,  0.27640587,\n",
              "         -0.15164396,  0.25430372, -0.8608676 , -0.11117502,\n",
              "         -0.5252868 , -0.07216536,  0.02316949, -0.9069602 ,\n",
              "         -0.26114473,  0.19493026, -0.98034286, -0.70663923,\n",
              "         -0.25509965,  0.25409326,  0.1060916 , -0.11378517,\n",
              "         -0.35723025, -0.7799293 , -0.53064156, -0.42475328,\n",
              "         -0.66108644]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_key = jrand.PRNGKey(99)\n",
        "key, split_key = jrand.split(init_key)"
      ],
      "metadata": {
        "id": "OiIl31K0cQVj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_to_next_token = jrand.categorical(split_key, next_token_logit)\n",
        "next_to_next_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hMY9sAsCczWf",
        "outputId": "f492131d-f5db-494e-a73e-68de847c0b75"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[25]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(next_to_next_token.tolist()[0], itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7gpbNLGCc8k-",
        "outputId": "3c6eee54-844f-49ee-a275-0b1c59a0fe77"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_to_next_to_next_logit = state.apply_fn({\"params\": state.params}, next_to_next_token)"
      ],
      "metadata": {
        "id": "9yoh9KIXdby-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key, split_key = jrand.split(key)"
      ],
      "metadata": {
        "id": "eT4SCAXidmBi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_to_next_to_next_token = jrand.categorical(split_key, next_token_logit)\n",
        "\n",
        "next_to_next_to_next_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JE6B49q2dkNm",
        "outputId": "b286dd2a-26de-47ad-aa8b-147affd71381"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[59]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(next_to_next_to_next_token.tolist()[0], itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qGbhB8K7d2B0",
        "outputId": "4b3f0410-4c20-4a59-825c-45ee1eab8d92"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting together the generate code\n",
        "\n",
        "input_token = jnp.array([[52]], dtype=jnp.int32)\n",
        "key = jrand.PRNGKey(99)\n",
        "\n",
        "result = \"\"\n",
        "for i in range(100):\n",
        "  key, split_key = jrand.split(key)\n",
        "  next_token_logit = state.apply_fn({\"params\": state.params}, input_token)\n",
        "  next_token = jrand.categorical(split_key, next_token_logit)\n",
        "  next_token_decode = decode(next_token.tolist()[0], itos)\n",
        "  result = result + next_token_decode\n",
        "\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "keaylzQod6rh",
        "outputId": "b9ddf673-3350-4eda-c494-14739e7aa0b6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MuTqF\n",
            "d$oMJ\n",
            " CiSOzjIftBqertiG,3gdghx,,.V,d .zbfa'$fXoeyu'l!m:oaBBQRcrEttkQm3u-r.v3LgdMVfxsx-;ga!kcPW\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mathematical trick in attention"
      ],
      "metadata": {
        "id": "G78p73EKNOJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## doing bag of words\n",
        "basically, in B, T, C\n",
        "at t-th token in a row of batch, just sum all the values upto t."
      ],
      "metadata": {
        "id": "vWZlcN7aNQ6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate T, C and write code which works for T, C.\n",
        "# Then, vmap it for batch\n",
        "\n",
        "# Using tokens = 4\n",
        "# Using each token with channel = 2 to make it easy to visualize\n",
        "T, C = 4, 2\n",
        "\n",
        "key, split_key = jrand.split(jrand.PRNGKey(99))\n",
        "\n",
        "x = jrand.normal(split_key, (T, C))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4x3NkSoBNsTg",
        "outputId": "29df8df4-c30c-4515-dd6a-fb02ff488fbb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.2628779 , -0.1837252 ],\n",
              "       [ 0.38331428, -0.16180514],\n",
              "       [ 1.4986674 ,  1.10728   ],\n",
              "       [ 1.1535788 ,  0.9676542 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### version 1: using for loop"
      ],
      "metadata": {
        "id": "ZFlsH67YZqQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bow_attention(x: jnp.array, T: int, C: int):\n",
        "  \"\"\"Operates on a single row within batchs\n",
        "\n",
        "    It calculates bow attention by summing all\n",
        "    token channels prev + current token channels.\n",
        "  \"\"\"\n",
        "  xbow = jnp.zeros(shape=(T, C))\n",
        "  for token in range(T):\n",
        "    xprev = x[:token]\n",
        "    xcurrent = x[token:token+1]\n",
        "\n",
        "    current_bow = jnp.mean(jnp.concatenate([xprev, xcurrent], axis=0), axis=0)\n",
        "    xbow = xbow.at[token].set(current_bow)\n",
        "  return xbow"
      ],
      "metadata": {
        "id": "jtZjg_WyS3pD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_attention(x, T, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EwDgkObLJh5X",
        "outputId": "d5b57418-0ad6-4250-a904-b06cba67c385"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.2628779 , -0.1837252 ],\n",
              "       [ 0.3230961 , -0.17276517],\n",
              "       [ 0.7149532 ,  0.25391656],\n",
              "       [ 0.8246096 ,  0.432351  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test bow_attention using non-random tensor.\n",
        "test_numbers = jnp.arange(1, 5).reshape(-1, 1)\n",
        "test_arr = jnp.tile(test_numbers, (1, C))\n",
        "bow_attention(test_arr, T, C)"
      ],
      "metadata": {
        "id": "aDTyU_cJCQaW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "78df59e7-fcb5-46a5-f291-84b27bcd5bc9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1. , 1. ],\n",
              "       [1.5, 1.5],\n",
              "       [2. , 2. ],\n",
              "       [2.5, 2.5]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### version 2: Starting to write it using matmul"
      ],
      "metadata": {
        "id": "iCEfpKc4Juqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aDJaLAS9JyAy",
        "outputId": "b184fbb6-1984-462f-fc2f-a0318cc1ca95"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.2628779 , -0.1837252 ],\n",
              "       [ 0.38331428, -0.16180514],\n",
              "       [ 1.4986674 ,  1.10728   ],\n",
              "       [ 1.1535788 ,  0.9676542 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = jnp.array([[1.0, 0., 0., 0.],\n",
        " [0.5, 0.5, 0., 0.],\n",
        " [0.333, 0.333, 0.333, 0.],\n",
        " [0.25, 0.25, 0.25, 0.25]])"
      ],
      "metadata": {
        "id": "KseF9l2cJ550"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0HBRJlxnQ9Wu",
        "outputId": "d64d46f1-5a70-4a0a-b5aa-162e663a4df4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.sum(tril, axis=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SbHxqFspWcN0",
        "outputId": "e2c12441-0f53-4089-e9d2-f4cc5582019e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [4.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wei(T: int):\n",
        "  tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "  return tril/jnp.sum(tril, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "naS4RF-FWfEL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_wei(T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "W-cr82EcWq5P",
        "outputId": "183c0acb-3b7d-4ae6-938d-f5309a81654d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.5       , 0.        , 0.        ],\n",
              "       [0.33333334, 0.33333334, 0.33333334, 0.        ],\n",
              "       [0.25      , 0.25      , 0.25      , 0.25      ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting together the bow attention calculation using matmul\n",
        "def bow_attention_matmul(x: jnp.array, T: int, C: int):\n",
        "  tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "  wei = tril/jnp.sum(tril, axis=1, keepdims=True)\n",
        "\n",
        "  return jnp.dot(wei, x)\n"
      ],
      "metadata": {
        "id": "D2za5ZmdE9fu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_attention_matmul(x, T, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0P96Sm6qXHfi",
        "outputId": "97b3a863-f37b-4b8a-a013-fc8684468a89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.2628779 , -0.1837252 ],\n",
              "       [ 0.3230961 , -0.17276517],\n",
              "       [ 0.7149532 ,  0.25391656],\n",
              "       [ 0.8246096 ,  0.432351  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### version 3: use softmax to generate wei matrix\n",
        "so that it can be learnable?"
      ],
      "metadata": {
        "id": "odn4VPr3cdaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wFNaw1Ufcmk-",
        "outputId": "7f1d933c-70f6-4590-ac0b-caba1315f96e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you start wei as all zeros\n",
        "wei = jnp.zeros(shape=(T, T))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-5e1e7Bn0WhD",
        "outputId": "8154af63-e730-4293-b4c1-9ae178a067f5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but now, we modify wei such that whenever tril==0, we put -inf into wei\n",
        "wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HgL4FNfI0cFk",
        "outputId": "b92c5d51-59e6-4e38-d301-afb1b8fb2421"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[  0., -inf, -inf, -inf],\n",
              "       [  0.,   0., -inf, -inf],\n",
              "       [  0.,   0.,   0., -inf],\n",
              "       [  0.,   0.,   0.,   0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next we take softmax along row, that is dim==-1\n",
        "wei = nn.softmax(wei, axis=-1)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pMzvM4Q50loZ",
        "outputId": "d9963950-27d4-4dbf-8fd4-60dfdeb2692c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.5       , 0.        , 0.        ],\n",
              "       [0.33333334, 0.33333334, 0.33333334, 0.        ],\n",
              "       [0.25      , 0.25      , 0.25      , 0.25      ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_attention(x: jnp.array, T:int, C:int):\n",
        "  \"\"\"Calculates attention for a row of tokens.\"\"\"\n",
        "  tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "  wei = jnp.zeros(shape=(T, T))\n",
        "  wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "  wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "  return jnp.dot(wei, x)"
      ],
      "metadata": {
        "id": "NtMC5WcrdE7m"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_attention(x, T, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G5XZ1TjsdpSH",
        "outputId": "78156c42-9732-40c0-c589-a4e9d46ce119"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.2628779 , -0.1837252 ],\n",
              "       [ 0.3230961 , -0.17276517],\n",
              "       [ 0.7149532 ,  0.25391656],\n",
              "       [ 0.8246096 ,  0.432351  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_attention(test_arr, T, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rpe729Ygd2V6",
        "outputId": "50df8579-551f-4408-d476-0bad3ab7f502"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1. , 1. ],\n",
              "       [1.5, 1.5],\n",
              "       [2. , 2. ],\n",
              "       [2.5, 2.5]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_attention_batch = jax.vmap(calc_attention, in_axes=(0, None, None), out_axes=(0))"
      ],
      "metadata": {
        "id": "BQ_Sy-FEeHpx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T, C = 8, 65\n",
        "test_numbers = jnp.arange(1, T+1).reshape(-1, 1)\n",
        "test_arr = jnp.tile(test_numbers, (1, C))\n",
        "\n",
        "# add batch dimension to test_arr\n",
        "test_arr_batch = test_arr[None, :]"
      ],
      "metadata": {
        "id": "ZpQKVgZwebqK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test calc_attention_batch using get_batch\n",
        "calc_attention_batch(test_arr_batch, T, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fsnmMhRmePJR",
        "outputId": "598279b1-814b-4762-d6fe-7b9d213a64e3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ,\n",
              "         1.       , 1.       , 1.       , 1.       , 1.       ],\n",
              "        [1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ,\n",
              "         1.5      , 1.5      , 1.5      , 1.5      , 1.5      ],\n",
              "        [2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ,\n",
              "         2.       , 2.       , 2.       , 2.       , 2.       ],\n",
              "        [2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ,\n",
              "         2.5      , 2.5      , 2.5      , 2.5      , 2.5      ],\n",
              "        [3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ,\n",
              "         3.       , 3.       , 3.       , 3.       , 3.       ],\n",
              "        [3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ,\n",
              "         3.5      , 3.5      , 3.5      , 3.5      , 3.5      ],\n",
              "        [4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005,\n",
              "         4.0000005, 4.0000005, 4.0000005, 4.0000005, 4.0000005],\n",
              "        [4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ,\n",
              "         4.5      , 4.5      , 4.5      , 4.5      , 4.5      ]]],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting together new Bigram model"
      ],
      "metadata": {
        "id": "jegiwSi3fsMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLangModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens.\"\"\"\n",
        "\n",
        "    # generate em for each token. output: (T, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(token_embs)"
      ],
      "metadata": {
        "id": "PieI67T3gHcK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add positional embeddings to the above."
      ],
      "metadata": {
        "id": "xgPfy8ogiHyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_of_tokens_example = jnp.ones(shape=(1, 8))\n",
        "block_of_tokens_example, block_of_tokens_example.shape, block_of_tokens_example.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vZYnHm6djluj",
        "outputId": "3f8c847e-7c4e-4084-fdf9-00daf211c18a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([[1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32), (1, 8), 8)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_pos = block_of_tokens_example.shape[1]\n",
        "num_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "388ZajvbkPwp",
        "outputId": "26d26c42-e5f3-4979-d725-b98b874c4fb8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.arange(0, num_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MCYxlaI0kReC",
        "outputId": "3f81aa3c-825e-4eab-ab5f-4f99c7afc504"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "\n",
        "  block_size: int # T, i.e., number of tokens attention block is looking at once\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.block_size, features=self.n_embed)\n",
        "\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "\n",
        "    # generate em for each token. output: (T, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    ## get token positions.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n"
      ],
      "metadata": {
        "id": "wd0Z83BuiLQI"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding single head attention."
      ],
      "metadata": {
        "id": "YwcW1HNy2BI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (copy-pasting from top)\n",
        "# Here, wei has uniform attention scores to previous tokens.\n",
        "# That is token in Tth position, is assuming that\n",
        "# each previous token has same amount of info.\n",
        "\n",
        "# But we want each Tth token to learn what to pay attention to.\n",
        "\n",
        "# So, we have each token emit \"keys\" -- info I have\n",
        "# Each token will emit \"query\" -- what I'm looking for\n",
        "# wei becomes the dot prodct of \"keys\" and \"query\" -- higher the dot product higher the match between\n",
        "# what I'm look for and what some previous token has.\n",
        "def calc_attention(x: jnp.array, T:int, C:int):\n",
        "  \"\"\"Calculates attention for a row of tokens.\"\"\"\n",
        "  tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "  wei = jnp.zeros(shape=(T, T))\n",
        "  wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "  wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "  return jnp.dot(wei, x)"
      ],
      "metadata": {
        "id": "wC4gleJIy8Qo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_info_size = 16 # head_size, each token produces vector of this size for key, query\n",
        "\n",
        "# key, query will take vector of size C.\n",
        "# i.e., channels containing info of token and will output token_info_size\n",
        "key_layer = nn.Dense(token_info_size, use_bias=False)\n",
        "\n",
        "query_layer = nn.Dense(token_info_size, use_bias=False)"
      ],
      "metadata": {
        "id": "FHOVay-Y2Mss"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (tokens, channel info for each)\n",
        "# (T, C)\n",
        "\n",
        "# for easy visualization, T=4, C=2\n",
        "T=4; C=2\n",
        "x = jrand.normal(jrand.PRNGKey(999), shape=(T, C))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yFKElCQe3kvE",
        "outputId": "0d441264-57c2-4fab-e7e1-7b2770ee8660"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.27297866, -0.6993713 ],\n",
              "       [ 0.428855  , -1.5621939 ],\n",
              "       [-0.05503325,  0.18392533],\n",
              "       [-0.18410844,  0.53945136]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prng = jrand.PRNGKey(9999)\n",
        "key, split_key = jrand.split(prng)"
      ],
      "metadata": {
        "id": "4uGkOUsJ4df3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keys emitted by each token.\n",
        "kparams = key_layer.init(split_key, x)[\"params\"]\n",
        "keys = key_layer.apply({\"params\": kparams}, x)\n",
        "\n",
        "# queries emitted by each token\n",
        "# NOTE: each token parallely and indpendently emits its \"keys\" and \"queries\"\n",
        "qparams = query_layer.init(split_key, x)[\"params\"]\n",
        "queries = query_layer.apply({\"params\": qparams}, x)\n",
        "\n",
        "keys.shape, queries.shape # each are (T, 16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5Ku4_M434A7P",
        "outputId": "bb53f48c-2eb7-4035-cfdb-e01cd8723e0d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 16), (4, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW, wei becomes this dot product between keys and querys\n",
        "wei = jnp.dot(queries, keys.T)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kafXGmJ948bX",
        "outputId": "3f4d6c89-2318-41ec-dd96-0970b804404d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 6.0750933, 12.761856 , -1.5228109, -4.5677843],\n",
              "       [12.761856 , 27.052605 , -3.221544 , -9.631147 ],\n",
              "       [-1.5228109, -3.221544 ,  0.3838081,  1.1482861],\n",
              "       [-4.5677843, -9.631147 ,  1.1482861,  3.4396741]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "\n",
        "  # Don't initialize wei as zeros\n",
        "  # wei = jnp.zeros(shape=(T, T))\n",
        "  wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "  wei = nn.softmax(wei, axis=-1)\n",
        "  wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aCMiX_qF1K3L",
        "outputId": "d8b22528-19ce-4bdd-98d1-e6070286446b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [6.2173666e-07, 9.9999940e-01, 0.0000000e+00, 0.0000000e+00],\n",
              "       [1.2637094e-01, 2.3115156e-02, 8.5051382e-01, 0.0000000e+00],\n",
              "       [3.0229829e-04, 1.9118115e-06, 9.1810778e-02, 9.0788496e-01]],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each token also produces \"value\", which is what we would multiply with wei.\n",
        "# so, wei is attention score.\n",
        "# whenever the attention score is high, we want to take its value."
      ],
      "metadata": {
        "id": "VCpDFskA6PFT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combing things from above and adding value layer as well."
      ],
      "metadata": {
        "id": "XNYPY8vr6pQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (tokens, channel info for each)\n",
        "# (T, C)\n",
        "\n",
        "# for easy visualization, T=4, C=2\n",
        "T=4; C=2\n",
        "x = jrand.normal(jrand.PRNGKey(999), shape=(T, C))\n",
        "\n",
        "key, split_key = jrand.split(jrand.PRNGKey(9999))\n",
        "\n",
        "token_info_size = 16 # head_size\n",
        "\n",
        "key_layer = nn.Dense(token_info_size, use_bias=False)\n",
        "query_layer = nn.Dense(token_info_size, use_bias=False)\n",
        "value_layer = nn.Dense(token_info_size, use_bias=False)\n",
        "\n",
        "\n",
        "keys = key_layer.apply(key_layer.init(split_key, x), x) # (T, token_info_size)\n",
        "queries = query_layer.apply(query_layer.init(split_key, x), x)\n",
        "values = value_layer.apply(value_layer.init(split_key, x), x) # (T, token_info_size)\n",
        "\n",
        "tril = jnp.tril(jnp.ones(shape=(T, T)))\n",
        "\n",
        "wei = jnp.dot(queries, keys.T) # (T, T)\n",
        "wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "\n",
        "out = jnp.dot(wei, values) # (T, T) * (T, token_info_size)\n",
        "\n",
        "# shape should be (T, token_info_size)\n",
        "# i.e., (4, 16)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_3j_56B_6tms",
        "outputId": "b174d15b-8b94-41b5-cd33-52f500846559"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## self-attention vs cross-attention: https://youtu.be/kCc8FmEb1nY?t=4542"
      ],
      "metadata": {
        "id": "SdFA175m9cOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaled attention -- dividing wei*value by squared root of head_size https://youtu.be/kCc8FmEb1nY?t=4638"
      ],
      "metadata": {
        "id": "Xx8fa3aC-CLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wei = jnp.dot(queries, keys.T) * C**0.5 # (T, T)\n",
        "wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "\n",
        "out = jnp.dot(wei, values) # (T, T) * (T, token_info_size)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IAsVpe_RFfkJ",
        "outputId": "4565e71b-bfcf-4c2f-c7d5-3e9786244fec"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.15091053,  1.1747676 , -0.27543876,  0.6276668 , -0.6659185 ,\n",
              "        -0.7521053 ,  0.15832554,  0.61729145,  0.5173192 , -1.0826657 ,\n",
              "         0.4595548 ,  0.38114175,  0.36432883, -0.12410479, -0.28500274,\n",
              "         0.8726827 ],\n",
              "       [ 0.15494807,  2.420155  , -0.75046575,  1.4276459 , -1.2494795 ,\n",
              "        -1.4867611 ,  0.18499118,  1.4277841 ,  1.0585895 , -2.3402715 ,\n",
              "         0.8965928 ,  0.6221145 ,  1.0077578 , -0.24458581, -0.6518733 ,\n",
              "         1.8538882 ],\n",
              "       [-0.0108901 , -0.18261386,  0.05756752, -0.1084154 ,  0.09365092,\n",
              "         0.11186212, -0.01323292, -0.10853641, -0.07983959,  0.1771509 ,\n",
              "        -0.06739505, -0.04610366, -0.07736284,  0.01839836,  0.04952013,\n",
              "        -0.14017412],\n",
              "       [-0.08724618, -0.85421604,  0.22667341, -0.47580495,  0.46656573,\n",
              "         0.5378475 , -0.09476726, -0.47136265, -0.37513095,  0.8030861 ,\n",
              "        -0.32692865, -0.2536266 , -0.30200323,  0.08864281,  0.21657023,\n",
              "        -0.642643  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement self-attention head.\n",
        "(copy-pasting from above code mostly into Flax module.)"
      ],
      "metadata": {
        "id": "8DrZZTi7zZm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  token_info_size: int # head_size; how much (emb dim) info each token emits for keys, queries, values.\n",
        "\n",
        "  T: int # block size; number of tokens in a block\n",
        "  C: int # channel info size: size of info channel of each token.\n",
        "\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "\n",
        "    # key, query will take vector of size C.\n",
        "    # i.e., channels containing info of token and will output token_info_size\n",
        "    self.key_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.query_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.value_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens with info channels, like (8, 65).\"\"\"\n",
        "\n",
        "    # TODO(ntnsonti): Double check; but tril should not be learnable according cGPT.\n",
        "    tril = jnp.tril(jnp.ones(shape=(self.T, self.T)))\n",
        "\n",
        "    keys = self.key_layer(block_of_tokens_with_info_channels) # (T, token_info_size)\n",
        "    queries = self.query_layer(block_of_tokens_with_info_channels)\n",
        "    values = self.value_layer(block_of_tokens_with_info_channels)\n",
        "\n",
        "    # compute attention score.\n",
        "    wei = jnp.dot(queries, keys.T) * C**0.5 # (T, T)\n",
        "    wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "    wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "\n",
        "    out = jnp.dot(wei, values) # (T, T) * (T, token_info_size))\n",
        "    return out # (T, token_info_size)\n",
        ""
      ],
      "metadata": {
        "id": "eYy0Xn9F-ipr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/kCc8FmEb1nY?t=4819"
      ],
      "metadata": {
        "id": "hER4RpvY5lnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "\n",
        "  T: int # block size, i.e., number of tokens attention block is looking at once\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.T, features=self.n_embed)\n",
        "\n",
        "    self.self_attention_head = Head(token_info_size=self.n_embed, T=self.T, C=self.C)\n",
        "\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "\n",
        "    # generate em for each token. output: (T, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    ## get token positions.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    # feed x into self-attention head.\n",
        "    x = self.self_attention_head(x)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n",
        "\n",
        "    return token_logits\n"
      ],
      "metadata": {
        "id": "zV5KQ3OLGO_N"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traing the network."
      ],
      "metadata": {
        "id": "GBsD7xpOHMPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kgoUZysXICvH",
        "outputId": "0237348c-0582-4068-a93a-0176cc75fed3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T = 8"
      ],
      "metadata": {
        "id": "12OMA67VIFlh"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(vocab_size=65, n_embed=32, T=BLOCK_SIZE)\n",
        "\n",
        "# Now, our language model needs to accept a block of tokens, not one-char at a time.\n",
        "# We'll then make it accept a batch of blocks of tokens using vmap.\n",
        "sample_block_of_tokens = jnp.ones(shape=(T), dtype=jnp.int32)\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), sample_block_of_tokens)\n",
        "params = params[\"params\"]\n",
        "\n",
        "model_apply_batch = jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0))\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "\n",
        "opt = optax.adam(learning_rate=0.001)\n",
        "state = train_state.TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  batch = get_batch()\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  print(loss) if epoch%100==0 else None\n",
        "  state = state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xLPSyus-HWKi",
        "outputId": "23fe9b77-ca81-42f1-a982-1e0a9fd8eaca"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.204059\n",
            "3.9591136\n",
            "3.033705\n",
            "2.8353043\n",
            "3.6666312\n",
            "2.91698\n",
            "2.6496902\n",
            "2.8693812\n",
            "2.4801302\n",
            "2.4153466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-head attention https://youtu.be/kCc8FmEb1nY?t=4925"
      ],
      "metadata": {
        "id": "BN7SglxvNUUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (copy-pasting single head attention from above)\n",
        "class Head(nn.Module):\n",
        "  token_info_size: int # head_size; how much (emb dim) info each token emits for keys, queries, values.\n",
        "\n",
        "  T: int # block size; number of tokens in a block\n",
        "  C: int # channel info size: size of info channel of each token.\n",
        "\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "\n",
        "    # key, query will take vector of size C.\n",
        "    # i.e., channels containing info of token and will output token_info_size\n",
        "    self.key_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.query_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.value_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens with info channels, like (8, 65).\"\"\"\n",
        "\n",
        "    # TODO(ntnsonti): Double check; but tril should not be learnable according cGPT.\n",
        "    tril = jnp.tril(jnp.ones(shape=(self.T, self.T)))\n",
        "\n",
        "    keys = self.key_layer(block_of_tokens_with_info_channels) # (T, token_info_size)\n",
        "    queries = self.query_layer(block_of_tokens_with_info_channels)\n",
        "    values = self.value_layer(block_of_tokens_with_info_channels)\n",
        "\n",
        "    # compute attention score.\n",
        "    wei = jnp.dot(queries, keys.T) * C**0.5 # (T, T)\n",
        "    wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "    wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "\n",
        "    out = jnp.dot(wei, values) # (T, T) * (T, token_info_size))\n",
        "    return out # (T, token_info_size)\n",
        ""
      ],
      "metadata": {
        "id": "cza12RTpN-ua"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You just run multiple attention heads in parallel and concatenate their output along channel dimension, i.e., dim==-1"
      ],
      "metadata": {
        "id": "KiT6OH_WOBNf"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "x.append(1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PaqN5ymwP3cV",
        "outputId": "ebd55b49-8f8e-4797-b072-f03318fb4946"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  num_heads: int\n",
        "  token_info_size: int\n",
        "\n",
        "  T: int\n",
        "  C: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "\n",
        "    self.heads = [Head(token_info_size=self.token_info_size, T=self.T, C=self.C) for _ in range(self.num_heads)]\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array):\n",
        "    out_from_each_head = jnp.array([h(block_of_tokens_with_info_channels) for h in self.heads])\n",
        "    return jnp.concatenate(out_from_each_head, axis=-1)\n",
        "\n"
      ],
      "metadata": {
        "id": "FZCNtnFANWV_"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  features: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    self.ffwd = nn.Dense(self.features)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = nn.relu(self.ffwd(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "LgidCnE6co1o"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "\n",
        "  T: int # block size, i.e., number of tokens attention block is looking at once\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.T, features=self.n_embed)\n",
        "\n",
        "    # *** new ***\n",
        "    # Since, there are 4 heads, each head only needs to output token_info of size 8.\n",
        "    # Concantenate token_info from all 4 heards, gives us 32\n",
        "    self.self_attention_heads = MultiHeadAttention(num_heads=4, token_info_size=int(self.n_embed/4), T=self.T, C=self.C)\n",
        "\n",
        "    # *** new ***: do some computation after getting value scores from attention, instead of directly passing\n",
        "    # it to lang model head.\n",
        "    self.computation_feed_forward = FeedForward(features=10)\n",
        "\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "\n",
        "    # generate em for each token. output: (T, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    ## get token positions.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    # feed x into self-attention head.\n",
        "    x = self.self_attention_heads(x)\n",
        "\n",
        "    # do some computation on attention values\n",
        "    x = self.computation_feed_forward(x)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n",
        "\n",
        "    return token_logits\n"
      ],
      "metadata": {
        "id": "8og78QLYPPNF"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(vocab_size=65, n_embed=32, T=BLOCK_SIZE)\n",
        "\n",
        "# Now, our language model needs to accept a block of tokens, not one-char at a time.\n",
        "# We'll then make it accept a batch of blocks of tokens using vmap.\n",
        "sample_block_of_tokens = jnp.ones(shape=(T), dtype=jnp.int32)\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), sample_block_of_tokens)\n",
        "params = params[\"params\"]\n",
        "\n",
        "# model_apply_batch = jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0))\n",
        "\n",
        "# *** new ***: Fuck, jax.jit makes it so much faster even on GPU.\n",
        "model_apply_batch = jax.jit(jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0)))\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "\n",
        "opt = optax.adam(learning_rate=0.0005)\n",
        "state = train_state.TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt)\n",
        "\n",
        "for epoch in range(5000):\n",
        "  batch = get_batch()\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  print(loss) if epoch%100==0 else None\n",
        "  state = state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u3i62quMPv4d",
        "outputId": "3cd129df-e649-4a5d-9087-9d7278ca3018"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1726465\n",
            "4.061119\n",
            "3.741846\n",
            "3.013401\n",
            "3.3317478\n",
            "3.0211744\n",
            "3.2269092\n",
            "3.4045367\n",
            "2.9718127\n",
            "3.0332696\n",
            "2.7503564\n",
            "3.0296686\n",
            "3.317126\n",
            "3.2040827\n",
            "3.325369\n",
            "2.693917\n",
            "2.838383\n",
            "2.917241\n",
            "3.0178413\n",
            "2.3379703\n",
            "2.5787427\n",
            "2.8016653\n",
            "3.1963558\n",
            "2.600708\n",
            "2.7424903\n",
            "2.3033342\n",
            "2.5605736\n",
            "2.6453342\n",
            "2.6672292\n",
            "2.3056529\n",
            "2.6856613\n",
            "2.6005397\n",
            "2.4296987\n",
            "2.623204\n",
            "2.9177299\n",
            "2.4936001\n",
            "2.2371163\n",
            "3.3853207\n",
            "2.6467462\n",
            "2.3239803\n",
            "2.5612345\n",
            "2.8510518\n",
            "2.6556215\n",
            "2.5299249\n",
            "2.5539665\n",
            "2.0489898\n",
            "3.165544\n",
            "2.1014366\n",
            "2.513821\n",
            "3.0195866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NanoGPT -- final stretch\n",
        "- Create a block which does communication and computation.\n",
        "- Add ResNet skip connections\n",
        "- Add LayerNorm."
      ],
      "metadata": {
        "id": "-_JsJ5hoKQ-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  token_info_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # **new**: attention paper uses 4 times token_info_size when doing linear transformation.\n",
        "    # and then projects it back to token_info_size in linear transformation layer.\n",
        "    self.ffwd = nn.Dense(features=4 * self.token_info_size)\n",
        "\n",
        "    # **new**: projection layer, which goes back into residual pathway.\n",
        "    self.projection = nn.Dense(self.token_info_size)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = nn.relu(self.ffwd(x))\n",
        "    x = self.projection(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Wg9q_YpVhXsk"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (copy-pasting single head attention from above)\n",
        "class Head(nn.Module):\n",
        "  token_info_size: int # head_size; how much (emb dim) info each token emits for keys, queries, values.\n",
        "  T: int # block size; number of tokens in a block\n",
        "\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "\n",
        "    # key, query will take vector of size C.\n",
        "    # i.e., channels containing info of token and will output token_info_size\n",
        "    self.key_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.query_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.value_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens with info channels, like (8, 65).\"\"\"\n",
        "    # channel_info size\n",
        "    C = int(block_of_tokens_with_info_channels.shape[-1])\n",
        "\n",
        "    # TODO(ntnsonti): Double check; but tril should not be learnable according cGPT.\n",
        "    tril = jnp.tril(jnp.ones(shape=(self.T, self.T)))\n",
        "\n",
        "    keys = self.key_layer(block_of_tokens_with_info_channels) # (T, token_info_size)\n",
        "    queries = self.query_layer(block_of_tokens_with_info_channels)\n",
        "    values = self.value_layer(block_of_tokens_with_info_channels)\n",
        "\n",
        "    # compute attention score.\n",
        "    wei = jnp.dot(queries, keys.T) * C**0.5 # (T, T)\n",
        "    wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "    wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "    out = jnp.dot(wei, values) # (T, T) * (T, token_info_size))\n",
        "    return out # (T, token_info_size)\n",
        ""
      ],
      "metadata": {
        "id": "5sPyAoPr3JMb"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  num_heads: int\n",
        "  token_info_size: int\n",
        "  T: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "\n",
        "    self.heads = [\n",
        "        Head(token_info_size=self.token_info_size, T=self.T) for _ in range(self.num_heads)\n",
        "    ]\n",
        "\n",
        "    # **new**: projection is just a linear transformation after getting attention values.\n",
        "    # it goes back into residual pathway? https://youtu.be/kCc8FmEb1nY?t=5501\n",
        "    self.projection = nn.Dense(features=int(self.token_info_size*self.num_heads))\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array):\n",
        "    out_from_each_head = jnp.array([h(block_of_tokens_with_info_channels) for h in self.heads])\n",
        "    out_from_all_heads = jnp.concatenate(out_from_each_head, axis=-1)\n",
        "    return self.projection(out_from_all_heads)\n"
      ],
      "metadata": {
        "id": "ver-i314gzS8"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  num_heads: int\n",
        "  token_info_size: int\n",
        "  T: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "\n",
        "    self.self_attention_heads = MultiHeadAttention(num_heads=self.num_heads,\n",
        "                                                   token_info_size=int(self.token_info_size/self.num_heads),\n",
        "                                                   T=self.T)\n",
        "    self.computation_ffwd = FeedForward(token_info_size=self.token_info_size)\n",
        "\n",
        "    # Layer norm, normalizes along the row. So, for every row, i.e., every example, all the neuron activations\n",
        "    # would have zero mean and unit variance. It is same during training and serving.\n",
        "    # Apply LayerNorm before feeding the input x.\n",
        "    # Reference: https://youtu.be/kCc8FmEb1nY?t=5673\n",
        "    # In Batch Normalization, the normalization process ensures that each neuron has zero mean and unit variance\n",
        "    # across the batch dimension. For instance, with a batch size of 32 and a layer with 10 neurons, each of the 10 neurons\n",
        "    # will have zero mean and unit variance across the 32 examples in the batch.\n",
        "\n",
        "    # Layer Normalization, on the other hand, normalizes the activations along each example independently.\n",
        "    # This means for each example in the batch (i.e., along each row if the examples are represented in a matrix),\n",
        "    # all the neuron activations are normalized to have zero mean and unit variance. This normalization behavior\n",
        "    # remains consistent during both training and serving phases.\n",
        "    self.ln1 = nn.LayerNorm()\n",
        "    self.ln2 = nn.LayerNorm()\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # import pdb; pdb.set_trace()\n",
        "    # x = x + self.self_attention_heads(self.ln1(x))\n",
        "    # x = x + self.computation_ffwd(self.ln2(x))\n",
        "    x = x + self.self_attention_heads(x)\n",
        "    x = x + self.computation_ffwd(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IorA-nTOafwj"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing blocks\n",
        "# T=4; C=2\n",
        "# x = jrand.normal(jrand.PRNGKey(999), shape=(T, C))\n",
        "# block = Block(num_heads=1, token_info_size=2, T=T)\n",
        "# block.init(jrand.PRNGKey(99), x)"
      ],
      "metadata": {
        "id": "E8qMtdZKJDNK"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "\n",
        "  T: int # block size, i.e., number of tokens attention block is looking at once\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.T, features=self.n_embed)\n",
        "\n",
        "    # **new**: use blocks instead of single multihead attention\n",
        "    self.blocks = nn.Sequential([\n",
        "        Block(num_heads=4, token_info_size=int(self.n_embed/4), T=self.T),\n",
        "        Block(num_heads=4, token_info_size=int(self.n_embed/4), T=self.T),\n",
        "        Block(num_heads=4, token_info_size=int(self.n_embed/4), T=self.T),\n",
        "        nn.LayerNorm(), # TODO: I think my reduction_axis should be 0.\n",
        "        ])\n",
        "\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "\n",
        "    # generate em for each token. output: (T, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    ## get token positions.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    # feed x into self-attention head.\n",
        "    x = self.blocks(x)\n",
        "\n",
        "    # do some computation on attention values\n",
        "    x = self.computation_feed_forward(x)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n",
        "\n",
        "    return token_logits\n"
      ],
      "metadata": {
        "id": "gt-smdjzGXF9"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(vocab_size=65, n_embed=32, T=BLOCK_SIZE)\n",
        "\n",
        "# Now, our language model needs to accept a block of tokens, not one-char at a time.\n",
        "# We'll then make it accept a batch of blocks of tokens using vmap.\n",
        "sample_block_of_tokens = jnp.ones(shape=(T), dtype=jnp.int32)\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), sample_block_of_tokens)\n",
        "params = params[\"params\"]\n",
        "\n",
        "model_apply_batch = jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0))\n",
        "\n",
        "# *** new ***: Fuck, jax.jit makes it so much faster even on GPU.\n",
        "# model_apply_batch = jax.jit(jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0)))\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "\n",
        "opt = optax.adam(learning_rate=0.0005)\n",
        "state = train_state.TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt)\n",
        "\n",
        "for epoch in range(5000):\n",
        "  batch = get_batch()\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  print(loss) if epoch%100==0 else None\n",
        "  state = state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d6o5Cvy-5Q5E",
        "outputId": "ccce6683-572a-49f5-e0fb-8ae903c72af3"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Incompatible shapes for broadcasting: shapes=[(8, 8), (), (4, 4)]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_broadcast_shapes_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_shapes_uncached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Incompatible shapes for broadcasting: shapes={list(shapes)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(8, 8), (), (4, 4)]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-213-9dbb8c0556b5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# We'll then make it accept a batch of blocks of tokens using vmap.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample_block_of_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_with_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_block_of_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-212-892e35258dcd>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, block_of_tokens)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# feed x into self-attention head.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# do some computation on attention values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/linen/combinators.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Empty Sequential module {self.name}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-211-c075ea34ea36>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# x = x + self.self_attention_heads(self.ln1(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# x = x + self.computation_ffwd(self.ln2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation_ffwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-210-3e17c86d4d03>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, block_of_tokens_with_info_channels)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_of_tokens_with_info_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mout_from_each_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_of_tokens_with_info_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mout_from_all_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_from_each_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_from_all_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-210-3e17c86d4d03>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_of_tokens_with_info_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mout_from_each_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_of_tokens_with_info_channels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mout_from_all_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_from_each_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_from_all_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-206-bf9875f9e29e>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, block_of_tokens_with_info_channels)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# compute attention score.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;31m# (T, T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(acondition, if_true, if_false, size, fill_value, condition, x, y)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"size and fill_value arguments cannot be used in three-term where function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_where\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpromote_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m   \u001b[0mcondition_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0mis_always_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_broadcast_arrays\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    405\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinitely_equal_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m   \u001b[0mresult_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mresult_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_broadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Incompatible shapes for broadcasting: shapes={list(shapes)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(8, 8), (), (4, 4)]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New params\n",
        "- Batch size 64\n",
        "- Block size 256\n",
        "- Learning rate 0.00003\n",
        "- n_embed = 384\n",
        "- num_heads = 6\n",
        "- train_steps = 5000\n",
        "\n",
        "\n",
        "Add dropout"
      ],
      "metadata": {
        "id": "O_w6gxlV3oKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "  \"\"\"****Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int # number of vocabulary (number of rows of embedding table)\n",
        "  n_embed: int # embedding dim after lookup\n",
        "\n",
        "  T: int # block size, i.e., number of tokens attention block is looking at once\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    # number of channels you want to use for store info for each token.\n",
        "    self.C = self.vocab_size\n",
        "\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.n_embed)\n",
        "\n",
        "    self.pos_embedding_table = nn.Embed(num_embeddings=self.T, features=self.n_embed)\n",
        "\n",
        "    self.self_attention_heads = MultiHeadAttention(num_heads=4,\n",
        "                                                   token_info_size=int(self.n_embed/4),\n",
        "                                                   T=self.T)\n",
        "\n",
        "    # *** new ***: do some computation after getting value scores from attention, instead of directly passing\n",
        "    # it to lang model head.\n",
        "    self.computation_feed_forward = FeedForward(token_info_size=self.n_embed)\n",
        "\n",
        "    self.lang_model_head = nn.Dense(features=self.C)\n",
        "\n",
        "  def __call__(self, block_of_tokens: jnp.array):\n",
        "    \"\"\"Accepts a block of tokens, like [0, 1, 2, 3, 4, 5, 6, 7].\"\"\"\n",
        "\n",
        "    # generate em for each token. output: (T, n_embed)\n",
        "    token_embs = self.token_embedding_table(block_of_tokens)\n",
        "\n",
        "    # generate position embs for each token.\n",
        "    ## get token positions.\n",
        "    num_pos = block_of_tokens.shape[0]\n",
        "    positions = jnp.arange(0, num_pos)\n",
        "    pos_embs = self.pos_embedding_table(positions)\n",
        "\n",
        "    # generate actual input to attention, x, which is sum of token_embs + pos_embs\n",
        "    x = token_embs + pos_embs\n",
        "\n",
        "    x = self.self_attention_heads(x)\n",
        "\n",
        "    # do some computation on attention values\n",
        "    x = self.computation_feed_forward(x)\n",
        "\n",
        "    # generate logits for each token. output: (T, channels for info -- C)\n",
        "    token_logits = self.lang_model_head(x)\n",
        "\n",
        "    return token_logits"
      ],
      "metadata": {
        "id": "0jjLY6WpNleO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}