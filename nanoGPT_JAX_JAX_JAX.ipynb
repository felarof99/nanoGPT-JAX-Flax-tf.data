{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Use CPU runtime"
      ],
      "metadata": {
        "id": "16WhNG98gurS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6427RRkAbysU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4445c4-1d06-465a-8752-974f198e3077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-03 04:17:27--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-02-03 04:17:27 (118 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "!pip install -q --upgrade pip # To support manylinux2010 wheels.\n",
        "!pip install -q --upgrade jax jaxlib # CPU-only\n",
        "!pip install -q --upgrade jaxtyping\n",
        "!pip install -q --upgrade flax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import jaxtyping\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "OZqEXlfmfuwo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset pipeline"
      ],
      "metadata": {
        "id": "TeccUW1zg-V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Create chars vocubulary using all the unique characters in the text.\n",
        "chars = sorted(list(set(text)))\n",
        "VOCAB_SIZE = len(chars)\n",
        "\n",
        "# Create mapping from characters to integers.\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create reverse mapping from integers to characters.\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Create encode, decode function.\n",
        "def encode(s: str, stoi: Mapping[str, int]) -> List[int]:\n",
        "  return [stoi[c] for c in s]\n",
        "\n",
        "def decode(tokens: List[int], itos: Mapping[int, str]) -> str:\n",
        "  return ''.join([itos[i] for i in tokens])\n",
        "\n",
        "println(encode(\"hii there\", stoi), decode(encode(\"hii there\", stoi), itos))\n",
        "\n",
        "# Let's now split up the data into train and validation sets.\n",
        "data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# Below would result in a minibatch size of 32.\n",
        "BATCH_SIZE = 4 # how many independent sequences will we process in parallel?\n",
        "BLOCK_SIZE = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "val_dataset = (tf.data.Dataset.from_tensor_slices(val_data)\n",
        "                .batch(BLOCK_SIZE+1)\n",
        "                .map(lambda input: (input[:BLOCK_SIZE], input[1:BLOCK_SIZE+1]),\n",
        "                     num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .repeat()\n",
        "                .as_numpy_iterator())\n",
        "\n",
        "def get_batch(training: bool = True):\n",
        "  if not training:\n",
        "    val_batch = next(val_dataset)\n",
        "    return jnp.array(val_batch)\n",
        "\n",
        "  train_batch = next(train_dataset)\n",
        "  return jnp.array(train_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYycQ8ocg2sy",
        "outputId": "ef23f3eb-fc0f-40f1-baad-0e11b9b308bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-560c18dc3230>:24: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  data = jnp.array(encode(text, stoi), dtype=jnp.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch()\n",
        "println(\"inputs\", xb, \"inputs shape\", xb.shape)\n",
        "println(\"targets\", yb, \"targets shape\", yb.shape)\n",
        "for b in range(BATCH_SIZE): # batch dimension\n",
        "    for t in range(BLOCK_SIZE): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YTqHDylg6cY",
        "outputId": "387a1b78-5cfc-474d-ac3d-197d133062b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[18 47 56 57 58  1 15 47]\n",
            " [47 64 43 52 10  0 14 43]\n",
            " [53 56 43  1 61 43  1 54]\n",
            " [53 41 43 43 42  1 39 52]]\n",
            "inputs shape\n",
            "(4, 8)\n",
            "targets\n",
            "[[47 56 57 58  1 15 47 58]\n",
            " [64 43 52 10  0 14 43 44]\n",
            " [56 43  1 61 43  1 54 56]\n",
            " [41 43 43 42  1 39 52 63]]\n",
            "targets shape\n",
            "(4, 8)\n",
            "when input is [18] the target: 47\n",
            "when input is [18, 47] the target: 56\n",
            "when input is [18, 47, 56] the target: 57\n",
            "when input is [18, 47, 56, 57] the target: 58\n",
            "when input is [18, 47, 56, 57, 58] the target: 1\n",
            "when input is [18, 47, 56, 57, 58, 1] the target: 15\n",
            "when input is [18, 47, 56, 57, 58, 1, 15] the target: 47\n",
            "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
            "when input is [47] the target: 64\n",
            "when input is [47, 64] the target: 43\n",
            "when input is [47, 64, 43] the target: 52\n",
            "when input is [47, 64, 43, 52] the target: 10\n",
            "when input is [47, 64, 43, 52, 10] the target: 0\n",
            "when input is [47, 64, 43, 52, 10, 0] the target: 14\n",
            "when input is [47, 64, 43, 52, 10, 0, 14] the target: 43\n",
            "when input is [47, 64, 43, 52, 10, 0, 14, 43] the target: 44\n",
            "when input is [53] the target: 56\n",
            "when input is [53, 56] the target: 43\n",
            "when input is [53, 56, 43] the target: 1\n",
            "when input is [53, 56, 43, 1] the target: 61\n",
            "when input is [53, 56, 43, 1, 61] the target: 43\n",
            "when input is [53, 56, 43, 1, 61, 43] the target: 1\n",
            "when input is [53, 56, 43, 1, 61, 43, 1] the target: 54\n",
            "when input is [53, 56, 43, 1, 61, 43, 1, 54] the target: 56\n",
            "when input is [53] the target: 41\n",
            "when input is [53, 41] the target: 43\n",
            "when input is [53, 41, 43] the target: 43\n",
            "when input is [53, 41, 43, 43] the target: 42\n",
            "when input is [53, 41, 43, 43, 42] the target: 1\n",
            "when input is [53, 41, 43, 43, 42, 1] the target: 39\n",
            "when input is [53, 41, 43, 43, 42, 1, 39] the target: 52\n",
            "when input is [53, 41, 43, 43, 42, 1, 39, 52] the target: 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLangModel(nn.Module):\n",
        "  \"\"\"Reads one char and predicits the next char.\"\"\"\n",
        "  vocab_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    super().setup()\n",
        "    self.token_embedding_table = nn.Embed(num_embeddings=self.vocab_size, features=self.vocab_size)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    # Run block size inputs through embedding lookup.\n",
        "    # For each char, you get the logit predicted for that char.\n",
        "    # Then, you use the target token for that input and do a cross_entropy_loss.\n",
        "    logits = self.token_embedding_table(inputs)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "2eyyiNsw_YL-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In flax, you need to init the model with sample input that you would pass during each forward pass.\n",
        "# sample_input_row = jrand.randint(key=jrand.PRNGKey(99), minval=0, maxval=65, dtype=jnp.int32, shape=[1, BLOCK_SIZE])\n",
        "# sample_input_row"
      ],
      "metadata": {
        "id": "cKYsKCciBBqc",
        "outputId": "7872b35b-a1c9-4e6a-cf17-e7447b539895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[21, 23, 50, 28, 53, 55, 40, 29]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I'll make the flax model accept\n",
        "`[block size worth tokens, token]`\n",
        "\n",
        "# I'll then use vmap to make the model accept batches of data.\n",
        "`[batch dim, block size worth of tokens, token]`"
      ],
      "metadata": {
        "id": "bLZdjG6cVxij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input_row = jnp.ones(shape=[1, 1], dtype=jnp.int32)\n",
        "sample_input_row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkxBwwipK6Yc",
        "outputId": "ee92d451-94a5-4bcb-edcc-2bd06df125b6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLangModel(vocab_size=65)\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), sample_input_row)\n",
        "params = params[\"params\"]"
      ],
      "metadata": {
        "id": "dtb3A3KFCgF8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the model accepts batch of data\n",
        "`[batch, block of tokens, token_ids]`\n",
        "\n",
        "# To make it accept a batch, you need to use vmap."
      ],
      "metadata": {
        "id": "n0GfZYSQRE93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_apply_batch = jax.vmap(model.apply, in_axes=(None, 0), out_axes=(0))"
      ],
      "metadata": {
        "id": "nu8eFbAURSOy"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_apply_batch will accept\n",
        "# [batch, block of tokens, token ids]"
      ],
      "metadata": {
        "id": "eHo-zsVlWxNl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample forward pass, loss and backward pass."
      ],
      "metadata": {
        "id": "BPYIijJYDSV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = get_batch()\n",
        "inputs, targets = batch\n",
        "println(\"inputs\", inputs, inputs.shape, \"targets\", targets.shape)"
      ],
      "metadata": {
        "id": "x9UFVRpPDeZI",
        "outputId": "dd261d0b-ab60-4c81-d944-46bfc8340dab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "[[43  1 59 52 39 41 46 47]\n",
            " [45  1 57 41 39 56 57  1]\n",
            " [46 47 41 46  1 21  1 57]\n",
            " [53 59 50 42  1 46 47 42]]\n",
            "(4, 8)\n",
            "targets\n",
            "(4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model_apply_batch({\"params\": params}, inputs)"
      ],
      "metadata": {
        "id": "JNlkzt-IRr5O"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output should shape [4, 8, 65]\n",
        "# batch size = 4\n",
        "# block of tokens = 8\n",
        "# token_id to embedding = 65\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "id": "EiE6Yl0QXFml",
        "outputId": "3e75a29a-a2dd-4cb9-ff00-8f5b91491462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 8, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode a batch containing several input rows.\n",
        "println(\",\".join([decode(input_row, itos) for input_row in input_rows.tolist()]))"
      ],
      "metadata": {
        "id": "s1yjp5qdEKMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To do backward pass, you first need to compute grads.\n",
        "# In JAX, you use jax.grad to do a function transformation on the forward\n",
        "# function to get the gradient of the original function.\n",
        "# The grad is calculate wrt to the first param in the function.\n",
        "def forward_pass(params, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = model_apply_batch({\"params\": params}, inputs)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "09vAczHeGDis"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test forward pass.\n",
        "batch = get_batch()\n",
        "forward_pass(params=params, batch=batch)"
      ],
      "metadata": {
        "id": "KCh6wzoHYWDm",
        "outputId": "3aa050c3-2ea5-4dfc-a429-c3572afa67eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(4.179904, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_fn = jax.grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument."
      ],
      "metadata": {
        "id": "lJnYF1OtGzPq"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test forward pass and grads.\n",
        "# Grads would be the gradients for params.\n",
        "grads = grad_fn(params, batch)\n",
        "println(grads)"
      ],
      "metadata": {
        "id": "o3XKCpCJHQip",
        "outputId": "c2616851-74cd-4cac-e3c4-46babc994487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'token_embedding_table': {'embedding': Array([[0.00103511, 0.00097044, 0.00093559, ..., 0.00089521, 0.001064  ,\n",
            "        0.00093856],\n",
            "       [0.00152714, 0.00157371, 0.00149051, ..., 0.00147518, 0.00161794,\n",
            "        0.00155381],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ]], dtype=float32)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply grads to params to get new params.\n",
        "lr = 0.001\n",
        "println(\"params before:\", params)\n",
        "params = jax.tree_map(lambda p, g: p - lr * g, params, grads)\n",
        "println(\"params after:\", params)"
      ],
      "metadata": {
        "id": "qLHB0BpQHfI1",
        "outputId": "c8225ec3-d33b-4279-cf4b-558a90bf8b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params before:\n",
            "{'token_embedding_table': {'embedding': Array([[ 0.0752212 ,  0.01071652, -0.02585994, ..., -0.06997449,\n",
            "         0.10274917, -0.0226865 ],\n",
            "       [ 0.09400459,  0.12404279,  0.06972364, ...,  0.0593865 ,\n",
            "         0.1517611 ,  0.11131446],\n",
            "       [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
            "         0.01281604,  0.03134193],\n",
            "       ...,\n",
            "       [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
            "         0.11875169, -0.08573762],\n",
            "       [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
            "        -0.02818088,  0.13305528],\n",
            "       [-0.12428083, -0.13785616, -0.12170235, ..., -0.07394623,\n",
            "         0.19811267, -0.06473607]], dtype=float32)}}\n",
            "params after:\n",
            "{'token_embedding_table': {'embedding': Array([[ 0.07522016,  0.01071555, -0.02586087, ..., -0.06997538,\n",
            "         0.1027481 , -0.02268744],\n",
            "       [ 0.09400307,  0.12404122,  0.06972215, ...,  0.05938502,\n",
            "         0.15175948,  0.1113129 ],\n",
            "       [-0.0302137 , -0.07326671, -0.2515272 , ...,  0.20769818,\n",
            "         0.01281604,  0.03134193],\n",
            "       ...,\n",
            "       [-0.1394756 , -0.00640967, -0.07666602, ..., -0.2944119 ,\n",
            "         0.11875169, -0.08573762],\n",
            "       [ 0.05703759, -0.11280773,  0.2570641 , ..., -0.02059634,\n",
            "        -0.02818088,  0.13305528],\n",
            "       [-0.12428083, -0.13785616, -0.12170235, ..., -0.07394623,\n",
            "         0.19811267, -0.06473607]], dtype=float32)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing train step in flax"
      ],
      "metadata": {
        "id": "LKPwDOFmIaSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn({\"params\": params}, inputs)\n",
        "  # println(logits)\n",
        "  loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "XTFr_QJgIjE8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_fn = jax.value_and_grad(compute_loss, argnums=(0))"
      ],
      "metadata": {
        "id": "oHtnU9jjJf52"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = model.init(jrand.PRNGKey(90), jnp.ones(shape=(1, BLOCK_SIZE), dtype=jnp.int32))[\"params\"]\n",
        "opt = optax.adam(learning_rate=0.01)\n",
        "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=opt)\n",
        "\n",
        "for epoch in range(1000):\n",
        "  batch = get_batch()\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  print(loss) if epoch%100==0 else None\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtzCS8NzMJx9",
        "outputId": "0d8a84b6-0d88-46d0-bb41-902552e78a23"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1893883\n",
            "3.5785098\n",
            "3.2410522\n",
            "2.8703156\n",
            "2.7978456\n",
            "2.7443452\n",
            "2.7087464\n",
            "2.4864938\n",
            "2.5336409\n",
            "2.3312209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Code for generating tokens\n",
        "\n",
        "input_token = \"n\"\n",
        "encode(input_token, stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2BUBirGMWo6",
        "outputId": "da1fea0f-0bda-4d65-fcbe-4d863c361b7b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[52]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token = jnp.array([[52]], dtype=jnp.int32)\n",
        "input_token.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p4A99r1NKx-",
        "outputId": "ce8bcf94-27cf-4ad9-e0bc-c5a78c362105"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logit = state.apply_fn({\"params\": state.params}, input_token)"
      ],
      "metadata": {
        "id": "cJwJPnIlNSEP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logit.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df1oFKh9N4oj",
        "outputId": "ca64201e-8e15-4e2a-beb3-2cbf53547e82"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical trick in attention"
      ],
      "metadata": {
        "id": "G78p73EKNOJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## doing bag of words\n",
        "basically, in B, T, C\n",
        "at t-th token in a row of batch, just sum all the values upto t."
      ],
      "metadata": {
        "id": "vWZlcN7aNQ6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate T, C and write code which works for T, C.\n",
        "# Then, vmap it for batch\n",
        "T, C = BLOCK_SIZE, 65\n",
        "\n",
        "key, split_key = jrand.split(jrand.PRNGKey(99))\n",
        "\n",
        "x = jrand.normal(split_key, (T, C))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x3NkSoBNsTg",
        "outputId": "c3523c92-047e-4588-f60f-e5359c19f2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bow_attention(x: jnp.array):\n",
        "  \"\"\"Operates on a single row within batch, it calculates\n",
        "    bow attention by summing all token channels prev + current token channe\n",
        "\n",
        "  \"\"\"\n",
        "  T = BLOCK_SIZE # T == 8\n",
        "  xbow = jnp.zeros(shape=(T, C))\n",
        "  for token in range(T):\n",
        "    xprev = x[:token]\n",
        "    xcurrent = x[token:token+1]\n",
        "\n",
        "    current_bow = jnp.mean(jnp.concatenate([xprev, xcurrent], axis=0), axis=0)\n",
        "    xbow = xbow.at[token].set(current_bow)\n",
        "  return xbow"
      ],
      "metadata": {
        "id": "jtZjg_WyS3pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test bow_attention using non-random tensor.\n",
        "numbers = jnp.arange(1, 9).reshape(-1, 1)\n",
        "test_arr = jnp.tile(numbers, (1, 65))\n",
        "bow_attention(test_arr)"
      ],
      "metadata": {
        "id": "aDTyU_cJCQaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.make_jaxpr(bow_attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xymL9pqOUd4I",
        "outputId": "8e88acba-0598-44de-e820-18eb9c6b3d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function jax.make_jaxpr(bow_attention)(x: <function array at 0x7bdf6128c1f0>)>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NanoGPT"
      ],
      "metadata": {
        "id": "-_JsJ5hoKQ-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from functools import partial\n",
        "import pickle\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state\n",
        "from flax import serialization\n",
        "\n",
        "import optax\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config():\n",
        "    seed = 42\n",
        "    num_iterations = 20000\n",
        "    batch_size = 512\n",
        "    block_size = 64\n",
        "    learning_rate = 1e-4\n",
        "    embed_size = 256\n",
        "    num_heads = 8\n",
        "    head_size = 32\n",
        "    num_layers = 6\n",
        "    dropout = 0.2\n",
        "\n",
        "config = Config()\n",
        "\n",
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: \"\".join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Let's now split up the data into train and validation sets\n",
        "data = jnp.array(encode(text))\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "eval_data = data[n:]\n",
        "\n",
        "dynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n",
        "\n",
        "@jax.jit\n",
        "def get_batch(random_key, data):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    ix = jax.random.randint(random_key, shape=(config.batch_size, 1), minval=0, maxval=len(data)-config.block_size)\n",
        "    x = dynamic_slice_vmap(data, ix, (config.block_size,))\n",
        "    y = dynamic_slice_vmap(data, ix+1, (config.block_size,))\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "GXp557EPKSwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    epsilon: float = 1e-6\n",
        "    reduction_axes = -1\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        \"\"\"Applies layer normalization on the input.\"\"\"\n",
        "        # compute statistics\n",
        "        mean2 = jnp.mean(jax.lax.square(x), self.reduction_axes, keepdims=True)\n",
        "        mean = jnp.mean(x, self.reduction_axes, keepdims=True)\n",
        "        var = jnp.maximum(0., mean2 - jax.lax.square(mean))\n",
        "\n",
        "        # compute normalized inputs\n",
        "        x_norm = (x - mean) * jax.lax.rsqrt(var + self.epsilon)\n",
        "        return x_norm * self.param(\"scale\", nn.initializers.ones, x.shape[-1]) + self.param(\"bias\", nn.initializers.zeros, x.shape[-1])"
      ],
      "metadata": {
        "id": "54ZaAxlQJ__q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    head_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool):\n",
        "        key = nn.Dense(self.head_size, use_bias=False)(x)\n",
        "        query = nn.Dense(self.head_size, use_bias=False)(x)\n",
        "        value = nn.Dense(self.head_size, use_bias=False)(x)\n",
        "\n",
        "        tril = jnp.tril(jnp.ones((x.shape[-2], x.shape[-2])))\n",
        "        attention_weights = nn.softmax(jnp.where(tril == 0, -jnp.inf, query @ jnp.transpose(key, axes=(0, 2, 1))), axis=-1)\n",
        "        attention_weights = nn.Dropout(config.dropout)(attention_weights, deterministic=not training)\n",
        "        return attention_weights @ value\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    num_heads: int\n",
        "    head_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool):\n",
        "        x = jnp.concatenate([Attention(self.head_size)(x, training) for _ in range(self.num_heads)], axis=-1)\n",
        "        return nn.Dropout(config.dropout)(nn.Dense(self.num_heads*self.head_size)(x), deterministic=not training)\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool):\n",
        "        return nn.Dropout(config.dropout)(nn.Dense(config.embed_size)(nn.relu(nn.Dense(4*config.embed_size)(x))), deterministic=not training)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    num_heads: int\n",
        "    head_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool):\n",
        "        x = x + MultiHeadAttention(self.num_heads, self.head_size)(LayerNorm()(x), training)\n",
        "        return x + FeedFoward()(LayerNorm()(x), training)"
      ],
      "metadata": {
        "id": "u18njNd2J0Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    num_layers: int\n",
        "    num_heads: int\n",
        "    head_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool):\n",
        "        B, T = x.shape\n",
        "        x = nn.Embed(num_embeddings=vocab_size, features=config.embed_size)(x) + \\\n",
        "            nn.Embed(num_embeddings=config.block_size, features=config.embed_size)(jnp.arange(T))\n",
        "        for _ in range(self.num_layers):\n",
        "            x = Block(self.num_heads, self.head_size)(x, training)\n",
        "        x = nn.LayerNorm()(x)\n",
        "        return nn.Dense(vocab_size)(x)\n",
        "\n",
        "    def generate(self, random_key, params, context, length=50):\n",
        "        for _ in range(length):\n",
        "            logits = self.apply(params, context[:, -config.block_size:], training=False)\n",
        "            random_key, random_subkey = jax.random.split(random_key)\n",
        "            new_token = jax.random.categorical(random_subkey, logits[:, -1, :], axis=-1, shape=(1, 1))\n",
        "            context = jnp.concatenate([context, new_token], axis=1)\n",
        "        return context\n",
        "\n",
        "    @partial(jax.jit, static_argnames=(\"self\", \"length\"))\n",
        "    def generate_jit(self, random_key, params, length):\n",
        "        def scan_generate(carry, x):\n",
        "            key, context = carry\n",
        "            logits = self.apply(params, context, training=False)\n",
        "            random_key, random_subkey = jax.random.split(key)\n",
        "            new_token = jax.random.categorical(random_subkey, logits[:, -1, :], axis=-1, shape=(1, 1))\n",
        "            context = jnp.concatenate([context[:, 1:], new_token], axis=1)\n",
        "            return (random_key, context), new_token\n",
        "\n",
        "        _, new_tokens = jax.lax.scan(\n",
        "            scan_generate,\n",
        "            (random_key, jnp.zeros((1, config.block_size), dtype=jnp.int32)),\n",
        "            (),\n",
        "            length=length,\n",
        "        )\n",
        "        return new_tokens"
      ],
      "metadata": {
        "id": "TrHBW_n2KDrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "  key: jax.random.KeyArray\n",
        "\n",
        "def create_train_state(random_key, config):\n",
        "    model = Model(num_layers=config.num_layers, num_heads=config.num_heads, head_size=config.head_size)\n",
        "    params = model.init(random_key, jnp.ones((config.batch_size, config.block_size), dtype=jnp.int32), training=False)\n",
        "    tx = optax.adamw(config.learning_rate)\n",
        "    return TrainState.create(\n",
        "        apply_fn=model.apply, params=params, key=random_key, tx=tx)\n",
        "\n",
        "@jax.jit\n",
        "def train_step(state, x, y, dropout_key):\n",
        "    dropout_key = jax.random.fold_in(key=dropout_key, data=state.step)\n",
        "    def loss_fn(params):\n",
        "        logits = state.apply_fn(params, x, training=True, rngs={'dropout': dropout_key})\n",
        "        one_hot_encoded_labels = jax.nn.one_hot(y, num_classes=vocab_size)\n",
        "        return optax.softmax_cross_entropy(\n",
        "            logits=logits, labels=one_hot_encoded_labels\n",
        "        ).mean()\n",
        "\n",
        "    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "\n",
        "    return state, loss\n",
        "\n",
        "@jax.jit\n",
        "def eval_step(state, x, y):\n",
        "    logits = state.apply_fn(state.params, x, training=False)\n",
        "    one_hot_encoded_labels = jax.nn.one_hot(y, num_classes=vocab_size)\n",
        "    return optax.softmax_cross_entropy(\n",
        "        logits=logits, labels=one_hot_encoded_labels\n",
        "    ).mean()\n",
        "\n",
        "random_key = jax.random.PRNGKey(config.seed)\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "\n",
        "state = create_train_state(random_subkey, config)\n",
        "for i in range(config.num_iterations):\n",
        "    random_key, random_subkey = jax.random.split(random_key)\n",
        "    state, loss = train_step(state, *get_batch(random_subkey, train_data), random_subkey)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        random_key, random_subkey = jax.random.split(random_key)\n",
        "        print(f\"Step: {i}\\t train loss: {loss}\\t eval loss: {eval_step(state, *get_batch(random_subkey, eval_data))}\")\n",
        "\n",
        "params_state_dict = serialization.to_state_dict(state.params)\n",
        "with open(\"./outputs/params.pickle\", \"wb\") as params_file:\n",
        "    pickle.dump(params_state_dict, params_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAj1yJO3KH10",
        "outputId": "accf0e5e-b475-4c70-a26e-70f51bf91efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-af851a0849f1>:2: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
            "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
            "  key: jax.random.KeyArray\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 0\t train loss: 4.640990257263184\t eval loss: 4.123988628387451\n",
            "Step: 100\t train loss: 3.151776075363159\t eval loss: 3.0975451469421387\n",
            "Step: 200\t train loss: 2.798823356628418\t eval loss: 2.74839448928833\n"
          ]
        }
      ]
    }
  ]
}